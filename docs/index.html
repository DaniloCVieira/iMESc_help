<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="generator" content="pandoc" />

        <meta name="author" content="Danilo C Vieira" />
        <meta name="author" content="Gustavo Fonseca" />
    
    
    <title>iMESchelp!</title>

        <script src="site_libs/header-attrs-2.25/header-attrs.js"></script>
        <script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link href="site_libs/bootstrap-3.3.7/css/bootstrap.min.css" rel="stylesheet" />
        <script src="site_libs/bootstrap-3.3.7/js/bootstrap.min.js"></script>
        <script src="site_libs/navigation-1.1/tabsets.js"></script>
        <link href="site_libs/readthedown-0.1/readthedown.css" rel="stylesheet" />
        <link href="site_libs/readthedown-0.1/readthedown_fonts_embed.css" rel="stylesheet" />
        <script src="site_libs/readthedown-0.1/readthedown.js"></script>
    
    
        <style type="text/css">code{white-space: pre;}</style>
    <style type="text/css">
      pre > code.sourceCode { white-space: pre; position: relative; }
      pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
      pre > code.sourceCode > span:empty { height: 1.2em; }
      .sourceCode { overflow: visible; }
      code.sourceCode > span { color: inherit; text-decoration: inherit; }
      div.sourceCode { margin: 1em 0; }
      pre.sourceCode { margin: 0; }
      @media screen {
      div.sourceCode { overflow: auto; }
      }
      @media print {
      pre > code.sourceCode { white-space: pre-wrap; }
      pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
      }
      pre.numberSource code
        { counter-reset: source-line 0; }
      pre.numberSource code > span
        { position: relative; left: -4em; counter-increment: source-line; }
      pre.numberSource code > span > a:first-child::before
        { content: counter(source-line);
          position: relative; left: -1em; text-align: right; vertical-align: baseline;
          border: none; display: inline-block;
          -webkit-touch-callout: none; -webkit-user-select: none;
          -khtml-user-select: none; -moz-user-select: none;
          -ms-user-select: none; user-select: none;
          padding: 0 4px; width: 4em;
          background-color: #ffffff;
          color: #a0a0a0;
        }
      pre.numberSource { margin-left: 3em; border-left: 1px solid #a0a0a0;  padding-left: 4px; }
      div.sourceCode
        { color: #1f1c1b; background-color: #ffffff; }
      @media screen {
      pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
      }
      code span { color: #1f1c1b; } /* Normal */
      code span.al { color: #bf0303; background-color: #f7e6e6; font-weight: bold; } /* Alert */
      code span.an { color: #ca60ca; } /* Annotation */
      code span.at { color: #0057ae; } /* Attribute */
      code span.bn { color: #b08000; } /* BaseN */
      code span.bu { color: #644a9b; font-weight: bold; } /* BuiltIn */
      code span.cf { color: #1f1c1b; font-weight: bold; } /* ControlFlow */
      code span.ch { color: #924c9d; } /* Char */
      code span.cn { color: #aa5500; } /* Constant */
      code span.co { color: #898887; } /* Comment */
      code span.cv { color: #0095ff; } /* CommentVar */
      code span.do { color: #607880; } /* Documentation */
      code span.dt { color: #0057ae; } /* DataType */
      code span.dv { color: #b08000; } /* DecVal */
      code span.er { color: #bf0303; text-decoration: underline; } /* Error */
      code span.ex { color: #0095ff; font-weight: bold; } /* Extension */
      code span.fl { color: #b08000; } /* Float */
      code span.fu { color: #644a9b; } /* Function */
      code span.im { color: #ff5500; } /* Import */
      code span.in { color: #b08000; } /* Information */
      code span.kw { color: #1f1c1b; font-weight: bold; } /* Keyword */
      code span.op { color: #1f1c1b; } /* Operator */
      code span.ot { color: #006e28; } /* Other */
      code span.pp { color: #006e28; } /* Preprocessor */
      code span.re { color: #0057ae; background-color: #e0e9f8; } /* RegionMarker */
      code span.sc { color: #3daee9; } /* SpecialChar */
      code span.ss { color: #ff5500; } /* SpecialString */
      code span.st { color: #bf0303; } /* String */
      code span.va { color: #0057ae; } /* Variable */
      code span.vs { color: #bf0303; } /* VerbatimString */
      code span.wa { color: #bf0303; } /* Warning */
    </style>
    
        <link rel="stylesheet" href="styles.css" type="text/css" />
    
    <!-- tabsets -->
    <script>
      $(document).ready(function () {
	  window.buildTabsets("toc");
      });
      $(document).ready(function () {
	  $('.tabset-dropdown > .nav-tabs > li').click(function () {
	      $(this).parent().toggleClass('nav-tabs-open')
	  });
      });
    </script>

    <!-- code folding -->
    
    <!-- code download -->
    
    <!-- tabsets dropdown -->

    <style type="text/css">
      .tabset-dropdown > .nav-tabs {
	  display: inline-table;
	  max-height: 500px;
	  min-height: 44px;
	  overflow-y: auto;
	  background: white;
	  border: 1px solid #ddd;
	  border-radius: 4px;
      }
      
      .tabset-dropdown > .nav-tabs > li.active:before {
	  content: "";
	  font-family: 'Glyphicons Halflings';
	  display: inline-block;
	  padding: 10px;
	  border-right: 1px solid #ddd;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
	  content: "&#xe258;";
	  border: none;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
	  content: "";
	  font-family: 'Glyphicons Halflings';
	  display: inline-block;
	  padding: 10px;
	  border-right: 1px solid #ddd;
      }
      
      .tabset-dropdown > .nav-tabs > li.active {
	  display: block;
      }

      .tabset-dropdown > .nav-tabs > li.active a {
  	  padding: 0 15px !important;
      }

      .tabset-dropdown > .nav-tabs > li > a,
      .tabset-dropdown > .nav-tabs > li > a:focus,
      .tabset-dropdown > .nav-tabs > li > a:hover {
	  border: none;
	  display: inline-block;
	  border-radius: 4px;
	  background-color: transparent;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open > li {
	  display: block;
	  float: none;
      }
      
      .tabset-dropdown > .nav-tabs > li {
	  display: none;
	  margin-left: 0 !important;
      }
    </style>
    
</head>

<body class="preload">

   	
         <!-- readthedown start -->   
   <div id="content" data-toggle="wy-nav-shift">
     <nav id="nav-top" role="navigation" aria-label="top navigation">
       <a role="button" href="#" data-toggle="wy-nav-top"><span class="glyphicon glyphicon-menu-hamburger"></span></a>
     </nav>
         
   
        
      <h1 class="title">iMESc<sup>help!</sup></h1>
      
         <!-- readthedown authors -->
   <div id="sidebar">
    <h2><a href="#content">iMESc<sup>help!</sup></a></h2>
    <div id="toc">
      <ul>
      <li><a href="#introduction"
      id="toc-introduction">Introduction</a></li>
      <li><a href="#setup" id="toc-setup"><span
      class="toc-section-number">1</span> Setup</a></li>
      <li><a href="#layout" id="toc-layout"><span
      class="toc-section-number">2</span> Layout</a></li>
      <li><a href="#widgets" id="toc-widgets"><span
      class="toc-section-number">3</span> Widgets</a></li>
      <li><a href="#datalist" id="toc-datalist"><span
      class="toc-section-number">4</span> Datalist</a></li>
      <li><a href="#main-analyses" id="toc-main-analyses"><span
      class="toc-section-number">5</span> Main Analyses</a></li>
      <li><a href="#essentials-of-building-a-workflow-in-imesc"
      id="toc-essentials-of-building-a-workflow-in-imesc"><span
      class="toc-section-number">6</span> Essentials of Building a
      Workflow in iMESc</a>
      <ul>
      <li><a href="#create-datalists-based-on-model-specifications"
      id="toc-create-datalists-based-on-model-specifications"><span
      class="toc-section-number">6.1</span> Create Datalists Based on
      Model Specifications</a></li>
      <li><a href="#pre-processing" id="toc-pre-processing"><span
      class="toc-section-number">6.2</span> Pre-processing</a></li>
      <li><a href="#save-changes-and-models"
      id="toc-save-changes-and-models"><span
      class="toc-section-number">6.3</span> Save changes and
      models</a></li>
      <li><a href="#loading-and-downloading-a-savepoint"
      id="toc-loading-and-downloading-a-savepoint"><span
      class="toc-section-number">6.4</span> Loading and downloading a
      savepoint</a>
      <ul>
      <li><a href="#extracting-the-savepoint-results-by-r-code"
      id="toc-extracting-the-savepoint-results-by-r-code"><span
      class="toc-section-number">6.4.1</span> Extracting the Savepoint
      Results by R Code:</a></li>
      </ul></li>
      </ul></li>
      <li><a href="#pre-processing-tools"
      id="toc-pre-processing-tools"><span
      class="toc-section-number">7</span> Pre-processing Tools</a>
      <ul>
      <li><a href="#create-a-datalist" id="toc-create-a-datalist"><span
      class="toc-section-number">7.1</span> <img
      src="images/create_datalist_button.png" width="40" /> Create a
      Datalist</a>
      <ul>
      <li><a href="#upload" id="toc-upload"><span
      class="toc-section-number">7.1.1</span> Upload</a></li>
      <li><a href="#use-example-data" id="toc-use-example-data"><span
      class="toc-section-number">7.1.2</span> Use Example Data</a></li>
      </ul></li>
      <li><a href="#options" id="toc-options"><span
      class="toc-section-number">7.2</span> <img
      src="images/cog_button.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Options</a></li>
      <li><a href="#filter-observations"
      id="toc-filter-observations"><span
      class="toc-section-number">7.3</span> <img
      src="images/filter_obs.png"
      style="max-width: 44px; max-height: 31px" width="40" /> Filter
      observations</a></li>
      <li><a href="#filter-variables" id="toc-filter-variables"><span
      class="toc-section-number">7.4</span> <img
      src="images/filter_vars.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Filter variables</a></li>
      <li><a href="#transformations" id="toc-transformations"><span
      class="toc-section-number">7.5</span> <img
      src="images/transfs.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Transformations</a>
      <ul>
      <li><a href="#transformation" id="toc-transformation"><span
      class="toc-section-number">7.5.1</span> Transformation</a></li>
      <li><a href="#scale-and-centering"
      id="toc-scale-and-centering"><span
      class="toc-section-number">7.5.2</span> Scale and
      Centering</a></li>
      </ul></li>
      <li><a href="#data-imputation" id="toc-data-imputation"><span
      class="toc-section-number">7.6</span> <img src="images/imput.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Data imputation</a></li>
      <li><a href="#data-partition" id="toc-data-partition"><span
      class="toc-section-number">7.7</span> <img src="images/split.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Data partition</a></li>
      <li><a href="#aggregate" id="toc-aggregate"><span
      class="toc-section-number">7.8</span> <img src="images/agg.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Aggregate</a></li>
      <li><a href="#create-palette" id="toc-create-palette"><span
      class="toc-section-number">7.9</span> <img
      src="images/palette.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Create Palette</a></li>
      <li><a href="#savepoint" id="toc-savepoint"><span
      class="toc-section-number">7.10</span> <img
      src="images/savepoint.png"
      style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
      width="40" /> Savepoint</a></li>
      </ul></li>
      <li><a href="#sidebar-menu" id="toc-sidebar-menu"><span
      class="toc-section-number">8</span> Sidebar-menu</a>
      <ul>
      <li><a href="#data-bank" id="toc-data-bank"><span
      class="toc-section-number">8.1</span> <img
      src="images/side1_databank.png"
      style="max-width: 54px; max-height: 30px" width="40" /> Data
      Bank</a></li>
      <li><a href="#descriptive-tools" id="toc-descriptive-tools"><span
      class="toc-section-number">8.2</span> <img
      src="images/side2_desc.png"
      style="max-width: 54px; max-height: 30px" width="40" />
      Descriptive tools</a>
      <ul>
      <li><a href="#summary" id="toc-summary"><span
      class="toc-section-number">8.2.1</span> Summary</a></li>
      <li><a href="#ridges" id="toc-ridges"><span
      class="toc-section-number">8.2.2</span> Ridges</a></li>
      <li><a href="#pairplot" id="toc-pairplot"><span
      class="toc-section-number">8.2.3</span> Pairplot</a></li>
      <li><a href="#boxplot" id="toc-boxplot"><span
      class="toc-section-number">8.2.4</span> Boxplot</a></li>
      <li><a href="#correlation-plot" id="toc-correlation-plot"><span
      class="toc-section-number">8.2.5</span> Correlation plot</a></li>
      <li><a href="#mds" id="toc-mds"><span
      class="toc-section-number">8.2.6</span> MDS</a></li>
      <li><a href="#pca" id="toc-pca"><span
      class="toc-section-number">8.2.7</span> PCA</a></li>
      <li><a href="#rda" id="toc-rda"><span
      class="toc-section-number">8.2.8</span> RDA</a></li>
      <li><a href="#segrda" id="toc-segrda"><span
      class="toc-section-number">8.2.9</span> segRDA</a></li>
      </ul></li>
      <li><a href="#spatial-tools" id="toc-spatial-tools"><span
      class="toc-section-number">8.3</span> <img
      src="images/side3_map.png"
      style="max-width: 54px; max-height: 30px" width="40" /> Spatial
      Tools</a>
      <ul>
      <li><a href="#spatial-tools-module"
      id="toc-spatial-tools-module"><span
      class="toc-section-number">8.3.1</span> Spatial Tools
      Module</a></li>
      <li><a href="#spatial-representations"
      id="toc-spatial-representations"><span
      class="toc-section-number">8.3.2</span> Spatial
      Representations</a></li>
      <li><a href="#plot-engineers" id="toc-plot-engineers"><span
      class="toc-section-number">8.3.3</span> Plot Engineers</a></li>
      <li><a href="#interpolation-tunning"
      id="toc-interpolation-tunning"><span
      class="toc-section-number">8.3.4</span> Interpolation
      tunning</a></li>
      </ul></li>
      <li><a href="#biodiversity-tools"
      id="toc-biodiversity-tools"><span
      class="toc-section-number">8.4</span> <img
      src="images/side4_bio.png"
      style="max-width: 54px; max-height: 30px" width="40" />
      Biodiversity Tools</a>
      <ul>
      <li><a href="#biological-diversity-indexes"
      id="toc-biological-diversity-indexes"><span
      class="toc-section-number">8.4.1</span> Biological Diversity
      Indexes</a></li>
      <li><a href="#niche-analysis" id="toc-niche-analysis"><span
      class="toc-section-number">8.4.2</span> Niche Analysis</a></li>
      </ul></li>
      <li><a href="#unsupervised-algorithms"
      id="toc-unsupervised-algorithms"><span
      class="toc-section-number">8.5</span> <img
      src="images/side5_unsup.png"
      style="max-width: 54px; max-height: 30px" width="40" />
      Unsupervised Algorithms</a>
      <ul>
      <li><a href="#self-organizing-maps"
      id="toc-self-organizing-maps"><span
      class="toc-section-number">8.5.1</span> <img
      src="images/side6_som.png"
      style="max-width: 54px; max-height: 30px" width="40" />
      Self-Organizing maps</a></li>
      <li><a href="#hierarchical-clustering"
      id="toc-hierarchical-clustering"><span
      class="toc-section-number">8.5.2</span> <img
      src="images/side7_hc.png"
      style="max-width: 54px; max-height: 30px" width="40" />
      Hierarchical clustering</a></li>
      <li><a href="#k-means" id="toc-k-means"><span
      class="toc-section-number">8.5.3</span> <img
      src="images/side8_kmeans.png"
      style="max-width: 54px; max-height: 30px" width="40" />
      K-means</a></li>
      </ul></li>
      <li><a href="#supervised-algorithms"
      id="toc-supervised-algorithms"><span
      class="toc-section-number">8.6</span> <img
      src="images/side9_sup.png"
      style="max-width: 54px; max-height: 30px" width="40" /> Supervised
      Algorithms</a>
      <ul>
      <li><a href="#model-setup-2" id="toc-model-setup-2"><span
      class="toc-section-number">8.6.1</span> Model setup</a></li>
      <li><a href="#training" id="toc-training"><span
      class="toc-section-number">8.6.2</span> Training</a></li>
      <li><a href="#results-1" id="toc-results-1"><span
      class="toc-section-number">8.6.3</span> Results</a></li>
      <li><a href="#predict-1" id="toc-predict-1"><span
      class="toc-section-number">8.6.4</span> Predict</a></li>
      </ul></li>
      <li><a href="#compare-models" id="toc-compare-models"><span
      class="toc-section-number">8.7</span> <img
      src="images/side15_comp.png"
      style="max-width: 54px; max-height: 30px" width="40" /> Compare
      Models</a></li>
      </ul></li>
      <li><a href="#packages-functions"
      id="toc-packages-functions"><span
      class="toc-section-number">9</span> Packages &amp; functions</a>
      <ul>
      <li><a href="#table-1-packages-and-functions-for-analytical-tasks"
      id="toc-table-1-packages-and-functions-for-analytical-tasks"><span
      class="toc-section-number">9.1</span> <strong>Table 1: Packages
      and Functions for Analytical Tasks</strong></a></li>
      <li><a
      href="#table-2-packages-and-functions-used-throughout-the-app"
      id="toc-table-2-packages-and-functions-used-throughout-the-app"><span
      class="toc-section-number">9.2</span> <strong>Table 2: Packages
      and Functions Used Throughout the App</strong></a></li>
      </ul></li>
      <li><a href="#model-specific-tunning-supervised-alorithms"
      id="toc-model-specific-tunning-supervised-alorithms"><span
      class="toc-section-number">10</span> Model-specific tunning
      (Supervised alorithms)</a>
      <ul>
      <li><a href="#random-forest" id="toc-random-forest"><span
      class="toc-section-number">10.1</span> Random Forest</a></li>
      <li><a href="#naive-bayes" id="toc-naive-bayes"><span
      class="toc-section-number">10.2</span> Naive Bayes</a></li>
      <li><a href="#k-nearest-neighbors"
      id="toc-k-nearest-neighbors"><span
      class="toc-section-number">10.3</span> k-Nearest
      Neighbors</a></li>
      <li><a href="#stochastic-gradient-boosting"
      id="toc-stochastic-gradient-boosting"><span
      class="toc-section-number">10.4</span> Stochastic Gradient
      Boosting</a></li>
      <li><a href="#self-organizing-maps-1"
      id="toc-self-organizing-maps-1"><span
      class="toc-section-number">10.5</span> Self-Organizing
      Maps</a></li>
      <li><a href="#generalized-linear-model"
      id="toc-generalized-linear-model"><span
      class="toc-section-number">10.6</span> Generalized Linear
      Model</a></li>
      <li><a href="#stacked-autoencoder-deep-neural-network"
      id="toc-stacked-autoencoder-deep-neural-network"><span
      class="toc-section-number">10.7</span> Stacked AutoEncoder Deep
      Neural Network</a></li>
      <li><a href="#conditional-inference-random-forest"
      id="toc-conditional-inference-random-forest"><span
      class="toc-section-number">10.8</span> Conditional Inference
      Random Forest</a></li>
      <li><a href="#gaussian-process-with-radial-basis-function-kernel"
      id="toc-gaussian-process-with-radial-basis-function-kernel"><span
      class="toc-section-number">10.9</span> Gaussian Process with
      Radial Basis Function Kernel</a></li>
      <li><a
      href="#svmlinear---support-vector-machines-with-linear-kernel"
      id="toc-svmlinear---support-vector-machines-with-linear-kernel"><span
      class="toc-section-number">10.10</span> svmLinear - Support Vector
      Machines with Linear Kernel</a></li>
      <li><a
      href="#svmradial---support-vector-machines-with-radial-basis-function-kernel"
      id="toc-svmradial---support-vector-machines-with-radial-basis-function-kernel"><span
      class="toc-section-number">10.11</span> svmRadial - Support Vector
      Machines with Radial Basis Function Kernel</a></li>
      <li><a
      href="#svmradialcost---support-vector-machines-with-radial-basis-function-kernel"
      id="toc-svmradialcost---support-vector-machines-with-radial-basis-function-kernel"><span
      class="toc-section-number">10.12</span> svmRadialCost - Support
      Vector Machines with Radial Basis Function Kernel</a></li>
      <li><a href="#avnnet---model-averaged-neural-network"
      id="toc-avnnet---model-averaged-neural-network"><span
      class="toc-section-number">10.13</span> avNNet - Model Averaged
      Neural Network</a></li>
      <li><a href="#nnet---neural-network"
      id="toc-nnet---neural-network"><span
      class="toc-section-number">10.14</span> nnet - Neural
      Network</a></li>
      <li><a href="#pcannet---neural-networks-with-feature-extraction"
      id="toc-pcannet---neural-networks-with-feature-extraction"><span
      class="toc-section-number">10.15</span> pcaNNet - Neural Networks
      with Feature Extraction</a></li>
      <li><a href="#rpart---cart" id="toc-rpart---cart"><span
      class="toc-section-number">10.16</span> rpart - CART</a></li>
      <li><a
      href="#monmlp---monotone-multi-layer-perceptron-neural-network"
      id="toc-monmlp---monotone-multi-layer-perceptron-neural-network"><span
      class="toc-section-number">10.17</span> monmlp - Monotone
      Multi-Layer Perceptron Neural Network</a></li>
      <li><a href="#mlpml---multi-layer-perceptron-with-multiple-layers"
      id="toc-mlpml---multi-layer-perceptron-with-multiple-layers"><span
      class="toc-section-number">10.18</span> mlpML - Multi-Layer
      Perceptron, with multiple layers</a></li>
      <li><a href="#evtree---tree-models-from-genetic-algorithms"
      id="toc-evtree---tree-models-from-genetic-algorithms"><span
      class="toc-section-number">10.19</span> evtree - Tree Models from
      Genetic Algorithms</a></li>
      </ul></li>
      <li><a href="#references" id="toc-references"><span
      class="toc-section-number">11</span> References</a></li>
      </ul>
    </div>
    <div id="postamble" data-toggle="wy-nav-shift" class="status">
                  <p class="author"><span class="glyphicon glyphicon-user"></span> Danilo
C Vieira</p>
                        <p class="author"><span class="glyphicon glyphicon-user"></span> Gustavo
Fonseca</p>
                      </div>
   </div>
     

   
      
   
<!-- Don't indent these lines or it will mess pre blocks indentation --> 
<div id="main">
<head>
<script type="text/javascript"
            src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>
    
</head>
<div id="introduction" class="section level1 unnumbered">
<h1 class="unnumbered">Introduction</h1>
<p>Welcome to the <span
style="font-family: &#39;Alata&#39;, sans-serif; color: #05668D;">iMESc<sup>help</sup></span>,
your comprehensive guide to use <span
style="font-family: &#39;Alata&#39;, sans-serif; color: #05668D;">iMESc:</span><span
style="font-family: &#39;Alata&#39;, sans-serif; color: #05668D;  font-style: italic;">an
interactive machine learning app designed to analyze environmental
data</span>. iMESc is a shiny-based application that allows the
performance of end-to-end machine learning workflows. It provides a wide
range of resources to meet the various needs of environmental scientist,
making it a versatile tool for data analysis.</p>
<p>This manual is organized into the following sections:</p>
<div id="intro_content">
<ol style="list-style-type: decimal">
<li><p><strong>Setup</strong>: Step-by-step instructions to run <span
style="font-family: &#39;Alata&#39;, sans-serif;">iMESc</span>.</p></li>
<li><p><strong>Layout</strong>: The dashboard organization.</p></li>
<li><p><strong>Widgets</strong>: The interactive widgets used in <span
style="font-family: &#39;Alata&#39;, sans-serif;">iMESc</span>, such as
buttons, dropdowns, and checkboxes, which enable seamless interactions
with the app.</p></li>
<li><p><strong>Datalist</strong>: Exploring the core concept of
Datalists and their attributes.</p></li>
<li><p><strong>Essentials of Building a Workflow in iMESc:</strong>
Generic workflow steps commonly encountered while using <span
style="font-family: &#39;Alata&#39;, sans-serif;">iMESc</span>.</p></li>
<li><p><strong>Pre-processing Tools</strong>: In-depth coverage of the
tools available for pre-processing data, including Datalist creation and
data transformation.</p></li>
<li><p><strong>Sidebar-menu</strong>: Details about the modules,
analyses and algorithms, parametrization, and results.</p></li>
<li><p><strong>Packages &amp; Functions</strong>: Details about the main
R packages and functions used in iMESc, along with their respective
versions and analytical tasks.</p></li>
</ol>
</div>
</div>
<div id="setup" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Setup</h1>
<ol style="list-style-type: decimal">
<li><p>Install <a href="https://cran.r-project.org/">R</a> and <a
href="https://www.rstudio.com/products/rstudio/download/">RStudio</a> if
you haven’t done so already;</p></li>
<li><p>Once installed, open the R studio;</p></li>
<li><p>Install shiny package if it is not already installed;</p></li>
</ol>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&#39;shiny&#39;</span>)</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li><div class="numbold">
<p>Run the code below.</p>
</div></li>
</ol>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>shiny<span class="sc">::</span><span class="fu">runGitHub</span>(<span class="st">&#39;iMESc&#39;</span>,<span class="st">&#39;DaniloCVieira&#39;</span>, <span class="at">ref=</span><span class="st">&#39;main&#39;</span>)</span></code></pre></div>
<p>When you use the iMESc app for the first time, it will automatically
install all the necessary packages, which may take several minutes to
complete. However, once the first installation is finished, subsequent
access of the app will be much faster. If the required packages are not
already loaded, they typically take several seconds to load. On the
other hand, if the packages are already loaded, iMESc will start almost
instantly.</p>
</div>
<div id="layout" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Layout</h1>
<div>
<p><span style="font-family: &#39;Alata&#39;, sans-serif;">iMESc</span>
is designed with a dashboard layout, consisting of three main
sections:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Pre-processing tools</strong> on the top-left containing
<a href="#widgets">widgets</a> for Datalist options and pre-processing
data.</p></li>
<li><p><strong>Sidebar-menu</strong> on the left-hand side containing
menu buttons.</p></li>
<li><p>The <strong>Main panel</strong> for viewing the analytical
tasks.</p></li>
</ol>
<p>Upon selecting a menu button, users will seamlessly navigate to a
sub-screen housing the selected module. Each module features a header
equipped with interactive widgets, along with multiple tab panels that
support various functionalities.</p>
<p>To ensure an optimal display of iMESc content, we strongly recommend
a minimum landscape resolution of 1377 x 768 pixels. Adhering to this
resolution, it will guarantee an enhanced user experience and proper
visualization of all elements on the screen.</p>
<div class="float">
<img src="images/imesc-layout.png" class="img1"
alt="Fig S2.1 - iMESc layout" />
<div class="figcaption">Fig S2.1 - iMESc layout</div>
</div>
</div>
</div>
<div id="widgets" class="section level1" number="3">
<h1><span class="header-section-number">3</span> Widgets</h1>
<p>The app is built using widgets: web elements that users interact
with. The standard <span
style="font-family: &#39;Alata&#39;, sans-serif;">iMESc</span> widgets
are:</p>
<table style="width:99%;">
<caption>Table S3.1 - iMESc widgets</caption>
<colgroup>
<col width="11%" />
<col width="60%" />
<col width="27%" />
</colgroup>
<thead>
<tr class="header">
<th>Widgets</th>
<th>Task</th>
<th></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Button</td>
<td>Performs an action when clicked</td>
<td><img src="gif/wid_button.gif" width="286" /></td>
</tr>
<tr class="even">
<td>Picker/Dropdown</td>
<td>Allows the user to select only one of a predefined set of mutually
exclusive options</td>
<td><img src="gif/wid_picker.gif" width="67" /></td>
</tr>
<tr class="odd">
<td>Checkbox</td>
<td>Interactive box that can be toggled by the user to indicate an
affirmative or negative choice</td>
<td><img src="gif/wid_check.gif" width="49" /></td>
</tr>
<tr class="even">
<td>Checkbox group</td>
<td>A group of check boxes</td>
<td><img src="gif/wid_checkgroup.gif" width="115" /></td>
</tr>
<tr class="odd">
<td>Radiobuttons</td>
<td>Allows the user to choose only one of a predefined set of mutually
exclusive options</td>
<td><img src="gif/wid_radio.gif" width="366" /></td>
</tr>
<tr class="even">
<td>File</td>
<td>A file upload control wizard</td>
<td><img src="gif/wid_file.gif" width="328" /></td>
</tr>
<tr class="odd">
<td>Numeric</td>
<td>A field to enter numbers</td>
<td><img src="gif/wid_num.gif" width="90" /></td>
</tr>
<tr class="even">
<td>Text</td>
<td>A field to enter text</td>
<td><img src="gif/wid_text.gif" width="110" /></td>
</tr>
</tbody>
</table>
</div>
<div id="datalist" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Datalist</h1>
<p>iMESc manages data through <strong>Datalists</strong> <a
href="#fig_datalist">Fig S4.1</a>, which can include sheets and
shape-files (user-provided). The sheets are internally treated as
data.frame objects in R, where rows represent observations and columns
represent variables. Matching observations among these attributes,
regardless of the Datalists they come from, is achieved based on the row
names, ensuring data consistency. <span class="empha"><strong><em>To
ensure proper handling of the sheets-attributes, you must provide a
unique ID and place it in the first column when uploading the
data</em></strong></span>. iMESc automatically removes this first column
and adds it as the row names of the respective attribute. Decimals in
iMESc are represented with dots (e.g. 1/2 =0.5), check it before
uploading a file.</p>
<p><span class="empha"><strong>Required</strong></span></p>
<table>
<colgroup>
<col width="30%" />
<col width="70%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Numeric-Attribute</strong></td>
<td>Numerical data with continuous or discrete variables.</td>
</tr>
</tbody>
</table>
<p><span style="empha"><strong>Optional</strong></span></p>
<table>
<colgroup>
<col width="15%" />
<col width="84%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Factor-Attribute:</strong></td>
<td>Categorical data. If not provided, iMESc automatically generates
this attribute as a sheet with a single column containing the IDs of the
Numeric-Attribute.</td>
</tr>
<tr class="even">
<td><strong>Coords-Attribute</strong></td>
<td>Geographical coordinates (Longitude, Latitude) <span
class="empha">represented in decimal degrees</span>, used for
spatialization of data within the Spatial Tools.</td>
</tr>
<tr class="odd">
<td><strong>Base-Shape-Attribute:</strong></td>
<td>A polygon shape to clip or interpolate spatialized data for map
generation.</td>
</tr>
<tr class="even">
<td><strong>Layer-Shape-Attrib</strong>ute:</td>
<td>Adds extra shapes for superimposition on maps.</td>
</tr>
<tr class="odd">
<td><strong>Extra-Shape Attribute:</strong></td>
<td>Users can add other shapes as Extra-Shape-Attribute to further
customize their maps.</td>
</tr>
</tbody>
</table>
<p>Furthermore, Datalists have the capacity to store models that have
been trained using the iMESc, permitting users to integrate and manage
predictive models along with their data sets. To access all the
available analyses in iMESc, you need to create a Datalist by either <a
href="#upload">uploading</a> your own data or using the <a
href="#use-example-data">example</a> data provided. For guidance on
uploading sheets and the required attribute formats, as well as how to
utilize the example Datalists, please refer to the “<a
href="#create-a-datalist">Creating a Datalist</a>” section.</p>
<div style="text-align: center">
<div class="float" id="fig_datalist">
<img src="images/imesc-datalist.png" width="400"
alt="Fig. S4.1 - Schematic representation of a Datalist and its associated attributes" />
<div class="figcaption">Fig. S4.1 - Schematic representation of a
Datalist and its associated attributes</div>
</div>
</div>
</div>
<div id="main-analyses" class="section level1" number="5">
<h1><span class="header-section-number">5</span> Main Analyses</h1>
<p>The table provided below serves as a convenient reference for the
main analyses utilized in iMESc. It displays their locations in the
sidebar menu, along with their abbreviations and corresponding packages.
For more comprehensive information about each analysis, you can refer to
their respective sections in this manual.</p>
<table style="width:98%;">
<colgroup>
<col width="14%" />
<col width="50%" />
<col width="8%" />
<col width="8%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th>Side Bar menu</th>
<th>Analyses</th>
<th>Abbreviation</th>
<th>Package</th>
<th>Author</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Descriptive tools</td>
<td>Pearson’s correlation</td>
<td>-</td>
<td>base</td>
<td>Pearson (1895)</td>
</tr>
<tr class="even">
<td></td>
<td>Kendell’s correlation</td>
<td>-</td>
<td>base</td>
<td>Kendall (1938)</td>
</tr>
<tr class="odd">
<td></td>
<td>Spearman’s correlation</td>
<td>-</td>
<td>base</td>
<td>Spearman (1904)</td>
</tr>
<tr class="even">
<td></td>
<td>Principal Component Analysis</td>
<td>PCA</td>
<td>base</td>
<td>Pearson (1901)</td>
</tr>
<tr class="odd">
<td></td>
<td>Nonmetric Multidimensional Scaling</td>
<td>MDS</td>
<td>vegan</td>
<td>Legendre &amp; Anderson (1999)</td>
</tr>
<tr class="even">
<td></td>
<td>Redundancy Analyses</td>
<td>RDA</td>
<td>vegan</td>
<td>Blanchet et al. (2008)</td>
</tr>
<tr class="odd">
<td></td>
<td>Piecewise Redundancy Analyses</td>
<td>pwRDA</td>
<td>segRDA</td>
<td>Vieira (2019)</td>
</tr>
<tr class="even">
<td>Spatial tools</td>
<td>Krigging</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td></td>
<td>Inverse Distance Weighting</td>
<td>idw</td>
<td>-</td>
<td>Shepard (1968)</td>
</tr>
<tr class="even">
<td></td>
<td>K-Nearest neighbor</td>
<td>KNN</td>
<td>stats</td>
<td>Fix &amp; Hodges (1951)</td>
</tr>
<tr class="odd">
<td></td>
<td>Support Vector Machine with Radial Basis Function Kernel</td>
<td>svmRadial</td>
<td>kernlab</td>
<td>Karatzoglou et.al (2004)</td>
</tr>
<tr class="even">
<td></td>
<td>Gaussian Process with Radial Basis Function Kernel</td>
<td>gaussprRadial</td>
<td>kernlab</td>
<td>Karatzoglou et.al (2004)</td>
</tr>
<tr class="odd">
<td></td>
<td>Support Vector Machine with Radial Basis Function Kernel and Cost
Parameter Optimization</td>
<td>svmRadialCost</td>
<td>kernlab</td>
<td>Karatzoglou et.al (2004)</td>
</tr>
<tr class="even">
<td>Unsupervised Algorithms</td>
<td>Sel-Organizing Maps</td>
<td>SOM</td>
<td>kohonen</td>
<td>Kohonen (1982)</td>
</tr>
<tr class="odd">
<td></td>
<td>Hierarchical Clustering</td>
<td>HC</td>
<td>factoextra</td>
<td>Sneath (1957)</td>
</tr>
<tr class="even">
<td></td>
<td>Random Forest</td>
<td>rf</td>
<td>randomForest</td>
<td>Breiman (2001)</td>
</tr>
<tr class="odd">
<td><p>Supervised</p>
<p>Algorithms</p></td>
<td>Stochastic gradient boosting</td>
<td>gbm</td>
<td>gbm</td>
<td>Friedman (2001)</td>
</tr>
<tr class="even">
<td></td>
<td>Conditional Inference Random Forest</td>
<td>cforest</td>
<td>party</td>
<td>Hothorn et al. (2006)</td>
</tr>
<tr class="odd">
<td></td>
<td>Recursive Partitioning and Regression Trees</td>
<td>rpart</td>
<td>rpart</td>
<td>Breiman et al. (1984)</td>
</tr>
<tr class="even">
<td></td>
<td>Tree models from Genetic Algorithms</td>
<td>evtree</td>
<td>evtree</td>
<td>Grubinger et al. (2014)</td>
</tr>
<tr class="odd">
<td></td>
<td>Naive Bayes</td>
<td>nb</td>
<td>klaR</td>
<td>Duda et al. (2012)</td>
</tr>
<tr class="even">
<td></td>
<td>K-Nearest Neighbors</td>
<td>knn</td>
<td>base</td>
<td>Fix &amp; Hodges (1951)</td>
</tr>
<tr class="odd">
<td></td>
<td>Self-Organizing Maps</td>
<td>xyf</td>
<td>kohonen</td>
<td>Shepard (1962)</td>
</tr>
<tr class="even">
<td></td>
<td>Generalized Linear Model</td>
<td>glm</td>
<td>base</td>
<td>Nelder &amp; Wedderburn (1972)</td>
</tr>
<tr class="odd">
<td></td>
<td>Gaussian Process with Radial Basis Function Kernel</td>
<td>gaussprRadial</td>
<td>kernlab</td>
<td>Karatzoglou et.al (2004)</td>
</tr>
<tr class="even">
<td></td>
<td>Support Vector Machine with Linear Kernel</td>
<td>svmLinear</td>
<td>kernlab</td>
<td>Karatzoglou et.al (2004)</td>
</tr>
<tr class="odd">
<td></td>
<td>Support Vector Machine with Radial Basis Function Kernel</td>
<td>svmRadial</td>
<td>kernlab</td>
<td>Karatzoglou et.al (2004)</td>
</tr>
<tr class="even">
<td></td>
<td>Support Vector Machine with Radial Basis Function Kernel and Cost
Parameter Optimization</td>
<td>svmRadialCost</td>
<td>kernlab</td>
<td>Karatzoglou et.al (2004)</td>
</tr>
<tr class="odd">
<td></td>
<td>Stacked AutoEncoder Deep Neural Network</td>
<td>dnn</td>
<td>deepnet</td>
<td>Vincent et al. (2010)</td>
</tr>
<tr class="even">
<td></td>
<td>Model Averaged Neural Network</td>
<td>avNNet</td>
<td>nnet</td>
<td>Ripley (1996)</td>
</tr>
<tr class="odd">
<td></td>
<td>Neural Network</td>
<td>nnet</td>
<td>nnet</td>
<td>Ripley (1996)</td>
</tr>
<tr class="even">
<td></td>
<td>Neural Networks with Feature Extraction</td>
<td>pcaNNet</td>
<td>nnet</td>
<td>Ripley (1996)</td>
</tr>
<tr class="odd">
<td></td>
<td>Monotone Multi-Layer Perceptron Neural Network</td>
<td>monmlp</td>
<td>monmlp</td>
<td>Lang (2005)</td>
</tr>
<tr class="even">
<td></td>
<td>Feature Selection using randomForest Genetic Algorithm</td>
<td>rfGA</td>
<td>caret</td>
<td>Kuhn (2008)</td>
</tr>
</tbody>
</table>
</div>
<div id="essentials-of-building-a-workflow-in-imesc"
class="section level1" number="6">
<h1><span class="header-section-number">6</span> Essentials of Building
a Workflow in iMESc</h1>
<p>In this section, we will cover the four recurring steps to construct
a workflow within iMESc:</p>
<div id="create-datalists-based-on-model-specifications"
class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Create Datalists
Based on Model Specifications</h2>
<div style="text-align: center">
<div class="float" id="fig_model_building">
<img src="images/imesc-essentials.png" width="500"
alt="Fig. S6.1 - Conceptual Setup for the Models available in iMESc." />
<div class="figcaption">Fig. S6.1 - Conceptual Setup for the Models
available in iMESc.</div>
</div>
</div>
<table>
<caption>Table S6.1 - Datalist Creation and Selection Based on Model
Specifications</caption>
<colgroup>
<col width="58%" />
<col width="41%" />
</colgroup>
<tbody>
<tr class="odd">
<td><a href="#create-a-datalist">Use pre-processing tools to Create
Datalists</a> with their associated attributes based on the chosen
analytical method.</td>
<td><img src="images/imesc-essentials-create-datalist.gif"
style="min-width: 400px;padding: 20px" width="300" /></td>
</tr>
<tr class="even">
<td>For unsupervised methods, only Numeric-Attribute (X) is needed.</td>
<td><img src="images/imesc-essentials-unsup.gif"
style="min-width: 400px;padding: 20px" width="400" /></td>
</tr>
<tr class="odd">
<td>For classification models, both Numeric-Attribute (X) and
Factor-Attribute (Y) are needed. X and Y can be from the same or
different Datalists.</td>
<td><img src="images/imesc-essentials-supervised_1.gif"
style="min-width: 400px;padding: 20px" width="400" /></td>
</tr>
<tr class="even">
<td>For regression models, X and Y are both Numeric-Attributes from
different Datalists.</td>
<td><img src="images/imesc-essentials-supervised-reg.gif"
style="min-width: 400px;padding: 20px" width="400" /></td>
</tr>
</tbody>
</table>
</div>
<div id="pre-processing" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Pre-processing</h2>
<table>
<caption>Table S6.2 - Common Pre-processing steps</caption>
<colgroup>
<col width="66%" />
<col width="33%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Use pre-processing tools to handle missing values (Data imputation
tool).</td>
<td><img src="images/imesc-essentials-pp-impute.gif"
style="min-width: 300px;padding: 20px" /></td>
</tr>
<tr class="even">
<td>Transform the data as needed (e.g., scaling, centering, log
transformations), especially for distance-based methods (e.g., PCA,
SOM).</td>
<td><img src="images/imesc-essentials-pp-transform.gif"
style="min-width: 300px;padding: 20px" /></td>
</tr>
<tr class="odd">
<td>Partition the Y data between training and testing for supervised
machine learning methods. This action creates a column in the Factor
Attribute indicating the partitioning.</td>
<td><img src="images/imesc-essentials-pp-partition.gif"
style="min-width: 300px;padding: 20px" /></td>
</tr>
</tbody>
</table>
</div>
<div id="save-changes-and-models" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Save changes and
models</h2>
<p>Saving data changes or trained models is a recurring step throughout
iMESc. Whenever saving is required, iMESc will indicate this with a
flashing-blue disc button . <img
src="images/imesc-essentials-save.gif" /></p>
<ul>
<li><p>Saving data changes can be done as new Datalists or overwrite
existing ones. Factor, Coords, and Shapes attributes are automatically
transferred to the new Datalist. Models previously saved in a Datalist
are not transferred.</p></li>
<li><p>Trained models are saved within the Datalist used as the
predictor (X). After training a model, users have the option to save it
as a new model or overwrite an existing one. This action creates a new
attribute within the Datalist (e.g., RF-Attribute for Random Forest
models).</p></li>
</ul>
</div>
<div id="loading-and-downloading-a-savepoint" class="section level2"
number="6.4">
<h2><span class="header-section-number">6.4</span> Loading and
downloading a savepoint</h2>
<div class="square">
<p><img src="images/imesc-essentials-savepoint.png"
style="float: right;" width="400" /></p>
<p>Download a save-point:</p>
<ol style="list-style-type: decimal">
<li><p>Open the pre-processing tools in iMESc.</p></li>
<li><p>Click the “Download” button in the “Create a savepoint”
section.</p></li>
<li><p>The save-point file (.rds) will be downloaded to the computer,
capturing your workspace, including all the Datalists and associated
models.</p></li>
</ol>
<ul>
<li><p>Restore a save-point:</p>
<ol style="list-style-type: decimal">
<li><p>Go to the pre-processing tools.</p></li>
<li><p>In the “Load a savepoint” section, use “Browse” to upload the
save-point file from your computer.</p></li>
<li><p>Click “Upload” or “Load” to restore your workspace to that
point.</p></li>
</ol></li>
</ul>
<p>Save-points are incredibly useful for preserving your analysis
progress and results. By downloading a save-point, you can conveniently
store your work, and later, by uploading it, you can seamlessly continue
your analysis from where you left off. This feature ensures that your
work remains intact, even if you close the session or access iMESc from
a different device.</p>
<p>Using save-points streamlines your workflow and enhances your overall
experience with iMESc, providing a reliable way to manage and preserve
your analysis outputs and data for future use.</p>
</div>
<div id="extracting-the-savepoint-results-by-r-code"
class="section level3" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Extracting the
Savepoint Results by R Code:</h3>
<p>You can extract specific results and attributes from the Savepoint
using R code. The iMESc is not required here. To do this, use the
following steps:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># Reading the Savepoint</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a>savepoint <span class="ot">&lt;-</span> <span class="fu">readRDS</span>(<span class="st">&quot;savepoint.rds&quot;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a>savepoint<span class="sc">$</span>saved_data     <span class="co"># To access all saved Datalists</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="fu">names</span>(savepoint<span class="sc">$</span>saved_data)     <span class="co"># To access the names of the saved Datalists</span></span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a><span class="co"># Accessing a specific Datalist named &quot;datalist_name&quot;</span></span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a>datalist_name <span class="ot">&lt;-</span> savepoint<span class="sc">$</span>saved_data[[<span class="st">&#39;datalist_name&#39;</span>]]</span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>datalist_name</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="co"># Accessing specific attributes within the Datalist</span></span>
<span id="cb3-11"><a href="#cb3-11" tabindex="-1"></a><span class="fu">attr</span>(datalist_name, <span class="st">&quot;factors&quot;</span>)       <span class="co"># To access the Factor-Attribute</span></span>
<span id="cb3-12"><a href="#cb3-12" tabindex="-1"></a><span class="fu">attr</span>(datalist_name, <span class="st">&quot;coords&quot;</span>)        <span class="co"># To access the Coords-Attribute</span></span>
<span id="cb3-13"><a href="#cb3-13" tabindex="-1"></a><span class="fu">attr</span>(datalist_name, <span class="st">&quot;base_shape&quot;</span>)    <span class="co"># To access the Base-Shape-Attribute</span></span>
<span id="cb3-14"><a href="#cb3-14" tabindex="-1"></a><span class="fu">attr</span>(datalist_name, <span class="st">&quot;layer_shape&quot;</span>)   <span class="co"># To access the Layer-Shape-Attribute</span></span>
<span id="cb3-15"><a href="#cb3-15" tabindex="-1"></a><span class="fu">attr</span>(datalist_name, <span class="st">&quot;extra_shape&quot;</span>)   <span class="co"># To access the Extra-Shapes-Attribute</span></span>
<span id="cb3-16"><a href="#cb3-16" tabindex="-1"></a></span>
<span id="cb3-17"><a href="#cb3-17" tabindex="-1"></a><span class="co"># To extract saved models</span></span>
<span id="cb3-18"><a href="#cb3-18" tabindex="-1"></a><span class="fu">attr</span>(datalist_name, <span class="st">&quot;som&quot;</span>)                 <span class="co"># To access all SOM models saved in the Datalist</span></span>
<span id="cb3-19"><a href="#cb3-19" tabindex="-1"></a><span class="fu">attr</span>(datalist_name, <span class="st">&quot;som&quot;</span>)[[<span class="st">&quot;model_name&quot;</span>]] <span class="co"># To access a saved SOM model named &#39;model_name&#39;</span></span>
<span id="cb3-20"><a href="#cb3-20" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" tabindex="-1"></a><span class="co"># To access other models, replace &quot;som&quot; with the corresponding model name:</span></span>
<span id="cb3-22"><a href="#cb3-22" tabindex="-1"></a><span class="co"># &#39;kmeans&#39; (k-Means), &#39;nb&#39; (Naive-Bayes), &#39;svm&#39; (Support-Machine Vector), &#39;knn&#39;(k-nearest neighbor), &#39;rf&#39; (Random Forest),</span></span>
<span id="cb3-23"><a href="#cb3-23" tabindex="-1"></a><span class="co"># &#39;sgboost&#39; (stochastic gradient boosting), &#39;xyf&#39; (supervised som).</span></span></code></pre></div>
<p>Note: Ensure that you specify the correct path and filename of your
save-point file in the <strong><code>readRDS</code></strong> function.
Modify “datalist_name” and “model_name” in the R code to access specific
Datalists and saved models, respectively.</p>
</div>
</div>
</div>
<div id="pre-processing-tools" class="section level1" number="7">
<h1><span class="header-section-number">7</span> Pre-processing
Tools</h1>
<div class="float">
<video src="images/t16-preproc.mp4" style="width: 600px;height: auto"
width="400" controls=""><a href="images/t16-preproc.mp4">Video S7 -
Pre-processing tools tutorial</a></video>
<div class="figcaption">Video S7 - Pre-processing tools tutorial</div>
</div>
<p>The Pre-processing Tools comprise a suite of functionalities for
manipulating and preparing Datalists. These tools assist in refining the
data, handling missing values, and generating custom palettes for
graphical outputs. Below are the details of each tool:</p>
<div id="create-a-datalist" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> <img
src="images/create_datalist_button.png" width="40" /> Create a
Datalist</h2>
<p>To begin working with iMESc, you need to create a Datalist, which
serves as the foundation for all analytical tasks. Click on “Create
Datalist button” to open a modal dialog for Datalist creation. All
analytical tasks in iMESc will require a Datalist, which can be uploaded
by the user or generated using example data.</p>
<div id="upload" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Upload</h3>
<ul>
<li><p><strong>Name the Datalist:</strong> Use the text widget to
provide a name for the Datalist.</p></li>
<li><p><strong>Numeric-Attribute</strong>: Upload a <em>.csv</em> or
<em>.xlsx</em> file containing the numeric variables. <span
class="empha">This file is mandatory and should include observations as
rows and variables as columns.</span>The first row must contain the
variable headings, and the first column should have observation labels.
Columns containing characters (text or mixed numeric and non-numeric
values) will be automatically transferred to the
Factor-Attribute.</p></li>
</ul>
<!-- -->
<ul>
<li><p><strong>Factor-Attribute:</strong> Upload a <em>.csv</em> or
<em>.xlsx</em> file containing categorical variables. <span
class="empha">This file should have observations as rows and categorical
variables as columns.</span> The first row must contain variable
headings, and the first column should have observation labels. If the
Factor-Attribute is not uploaded, the observation IDs will be used
automatically. This attribute is crucial for labeling, grouping, and
visualizing results based on factor levels. It can be replaced at any
time with a new one using the “Replace Factor-Attribute” button</p></li>
<li><p><strong>Coords-Attribute:</strong> Upload a <em>.csv</em> or
<em>.xlsx</em> file containing geographical coordinates. This file is
optional for creating a Datalist but required for generating maps. <span
class="empha">The first column should contain the observation labels,
the second column Longitude values, and the third column Latitude values
(both in decimal degrees).</span> The first row must contain the
coordinate headings.</p></li>
<li><p><strong>Base-Shape:</strong> Upload a single R file containing
the polygon shape, such as an oceanic basin outline, to be used
primarily with ggplot2 for map generation. This optional file provides
the foundational geographical context for your visualizations. It can be
generated using the SHP toolbox in the pre-processing tools, which
converts shapefiles (.shp, .shx, and .dbf files) into an R file suitable
for use as a base layer in ggplot2</p></li>
<li><p><strong>Layer-Shape:</strong> Upload a single R file containing
an additional shape layer, such as a continent shape, to be used
primarily with ggplot2 for map generation. This optional file can also
be created using the SHP toolbox available in the pre-processing
tools.</p></li>
</ul>
<div class="float">
<img src="images/imesc-essentials-create-datalist.gif" width="600"
alt="Gif S7.1 - Creating a Datalist from Upload" />
<div class="figcaption">Gif S7.1 - Creating a Datalist from Upload</div>
</div>
<div id="best-practices-when-uploading-your-sheet"
class="section level4 unnumbered">
<h4 class="unnumbered">Best practices when uploading your sheet</h4>
<ol style="list-style-type: decimal">
<li><p>Prepare your data: Use the first row as column headers and the
first column as observation labels.</p></li>
<li><p>Ensure each label is filled with unique information, removing any
duplicated names.</p></li>
<li><p>Check for empty cells in the observation label column.</p></li>
<li><p>Ensure that the column names are unique; duplicated names are not
allowed.</p></li>
<li><p>Avoid using cells with blank spaces or special symbols.</p></li>
<li><p>Avoid beginning variable names with a number.</p></li>
<li><p>Note that R is case-sensitive, so “name” is different from “Name”
or “NAME.”</p></li>
<li><p>Avoid blank rows and/or columns in your data.</p></li>
<li><p>Replace missing values with NA (not available).</p></li>
</ol>
</div>
</div>
<div id="use-example-data" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Use Example
Data</h3>
<p>This option allows users to explore the example data available in
<span style="font-family: &#39;Alata&#39;, sans-serif;">iMESc</span> .
After clicking on “Create a Datalist,” select the “Use example data”
radio-button to proceed with Datalist insertion. This action will insert
two Datalists from Araçá Bay, located on the southeastern coast of
Brazil:</p>
<ul>
<li><p><strong>envi_araca:</strong> Contains 141 samples with 9
environmental variables.</p></li>
<li><p><strong>nema_araca:</strong> Contains 141 samples with 194
free-living marine nematode species (southeastern coast of
Brazil).</p></li>
</ul>
<p>Both Datalists comprise five attributes: Numeric, Factor,
Coords-Attribute, Base-Shape, and Layer-Shape. Studies that explored
these data area include Corte et al., 2017, Checon et al., 2018 and
Vieira et al., 2021.</p>
<div class="float">
<img src="images/imesc-create-datalist-example.gif" width="600"
alt="Gif S7.2 - Creating a Datalist from Example Data" />
<div class="figcaption">Gif S7.2 - Creating a Datalist from Example
Data</div>
</div>
</div>
</div>
<div id="options" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> <img
src="images/cog_button.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Options</h2>
<div class="square">
<div class="float">
<img src="images/options.png" style="float: right" width="400"
alt="Fig. S7.2.1 - Options" />
<div class="figcaption">Fig. S7.2.1 - Options</div>
</div>
<p>This drop-down menu offers the user a range of tools for editing
Datalists.</p>
<div id="rename-datalist" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Rename
Datalist</h3>
<p>Change the name of a selected Datalis.</p>
</div>
<div id="merge-datalists" class="section level3" number="7.2.2">
<h3><span class="header-section-number">7.2.2</span> Merge
Datalists</h3>
<p>Combine two or more Datalists by columns or rows. This action affects
both Numeric and Factor-Attribute data. When merging by rows, it also
combines associated Coords-Attribute (if any). When merging by columns,
there is an option to fill missing columns with NA, or restrict the
Datalists to common columns.</p>
<p>Please note that saved models in one of the Datalists are not
transferred to the merged Datalist.</p>
</div>
<div id="exchange-factorvariables" class="section level3"
number="7.2.3">
<h3><span class="header-section-number">7.2.3</span> Exchange
Factor/Variables</h3>
<div class="float">
<video src="images/t8-exchange-numeric-factors.mp4"
style="width: 600px;height: auto" width="400" controls=""><a
href="images/t8-exchange-numeric-factors.mp4">Video S7.2.3 - Exchange
Factors/Variables tutorial</a></video>
<div class="figcaption">Video S7.2.3 - Exchange Factors/Variables
tutorial</div>
</div>
<p>The “Exchange Factors/Variables” functionality in iMESc allows you to
convert or transfer data between numeric and factor formats. This
powerful tool provides flexibility in handling your data and enables
transitions between different data types.</p>
<ol style="list-style-type: decimal">
<li><p>From Datalist Selector: Select the source Datalist from which you
want to exchange data.</p></li>
<li><p>From Attribute Selector: Within the selected Datalist, choose
between the Numeric or Factor Attribute that you wish to convert or
transfer.</p></li>
<li><p>To Datalist Selector: Select the target Datalist where you want
to transfer or convert the data.</p></li>
<li><p>To Attribute Selector: Within the target Datalist, specify
whether you want to convert the data to Numeric or Factor
format.</p></li>
</ol>
<div id="from-numeric" class="section level4 unnumbered">
<h4 class="unnumbered">From Numeric…</h4>
<ul>
<li><p><strong>To Numeric:</strong> This option allows you to copy or
transfer the selected numeric variables from the source Datalist to the
target Datalist while preserving their numeric format.</p></li>
<li><p><strong>To Factor:</strong> Convert the selected numeric
variables to factors. The default is to transform each unique numeric
value into a new level of the factor. You can use the “cut” option to
categorize the variables into specified bins or levels. The initial
guess of bins can be determined by three methods: Surges, Scott’s, or
Freedman-Diaconis. Additionally, you can manually define the number of
bins and also edit the names and order of the factor levels.</p></li>
</ul>
</div>
<div id="from-factor" class="section level4 unnumbered">
<h4 class="unnumbered">From Factor…</h4>
<ul>
<li><p><strong>To Factor:</strong> With this option, you can copy or
transfer the selected factors from the source Datalist to the target
Datalist, maintaining their original factor format.</p></li>
<li><p><strong>To Numeric:</strong> This conversion allows you to
convert the selected factors to numeric data before copying or moving
them. You have two types of conversions available:</p>
<ul>
<li><p>Binary: For each factor level, a single binary column is created,
where 1 indicates the class of that observation.</p></li>
<li><p>Integer: A single column is created, representing the numeric
(integer) representation of the factor levels (values).</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="replace-attributes" class="section level3" number="7.2.4">
<h3><span class="header-section-number">7.2.4</span> Replace
Attributes</h3>
<p>The “Replace Attribute” option allows users to update existing
Attributes within a Datalist by replacing them with new data from a CSV
file.</p>
</div>
<div id="edit-datalist-columns" class="section level3" number="7.2.5">
<h3><span class="header-section-number">7.2.5</span> Edit Datalist
Columns</h3>
<p>Modify the names of columns for both Numeric-Attributes and
Factor-Attributes, and remove columns.</p>
</div>
<div id="edit-model-names" class="section level3" number="7.2.6">
<h3><span class="header-section-number">7.2.6</span> Edit Model
names</h3>
<p>Allows you to edit the names of saved models.</p>
</div>
<div id="transpose-a-datalist" class="section level3" number="7.2.7">
<h3><span class="header-section-number">7.2.7</span> Transpose a
Datalist</h3>
<p>Rotate a Datalist (Numeric and Factor) from rows to columns. If a
Coords-Attribute is associated with the Datalist, it will be
removed.</p>
</div>
<div id="shp-toolbox" class="section level3" number="7.2.8">
<h3><span class="header-section-number">7.2.8</span> SHP toolbox</h3>
<div class="float" id="shp-toolbox-video">
<video src="images/t13-shp_toolbox.mp4" width="400" controls=""><a
href="images/t13-shp_toolbox.mp4">Video S7.2.8 - SHP toolbox
tutorial</a></video>
<div class="figcaption">Video S7.2.8 - SHP toolbox tutorial</div>
</div>
<p>This toolbox allows the creation of <a href="#Shape">Base-Shapes</a>,
<a href="#Shape">Layer-Shapes</a> and <a href="#Shape">Extra</a>
shapes.</p>
<div id="targets-upload" class="section level4 unnumbered">
<h4 class="unnumbered">Targets &amp; Upload</h4>
<ol style="list-style-type: decimal">
<li>Upload <a href="#shape-files">shape files*</a> at once</li>
<li>Select the Target Shape-Attribute: Base-Shape, Layer-Shape or
Extra-shape.</li>
<li>Select the Target Datalist.</li>
<li>Upload the shape files at once</li>
</ol>
</div>
<div id="shape-files" class="section level4 unnumbered"
data-link="shape files*">
<h4 class="unnumbered">shape files*</h4>
<p>Shapefiles are a simple, nontopological format for storing geometric
location and attribute information of geographic features. The shapefile
format defines the geometry and attributes of geographically referenced
features in three or more files with specific file extensions that
should be stored in the same project. It requires at least three
files:</p>
<p><em>.shp</em>: The main file that stores the feature geometry.</p>
<p><em>.shx</em>: The index file that stores the index of the feature
geometry.</p>
<p><em>.dbf</em>: The dBASE table that stores the attribute information
of features.</p>
<p>There is a one-to-one relationship between geometry and attributes,
which is based on record number. Attribute records in the dBASE file
must be in the same order as records in the main file.</p>
<p>Each file must have the same prefix, for example: basin.shp,
basin.shx, and basin.dbf</p>
</div>
<div id="filter-crop" class="section level4 unnumbered">
<h4 class="unnumbered">Filter &amp; Crop</h4>
<p>A setup box that appears after uploading and reading the shape files.
Options include filtering specific features, cropping to an existing
shape attribute, or manual cropping.</p>
</div>
<div id="create-save" class="section level4 unnumbered">
<h4 class="unnumbered">Create &amp; Save</h4>
<p>A setup box displayed after uploading and reading the shape files.
Use it to save the new shape in the target Datalist.</p>
</div>
</div>
<div id="run-script" class="section level3" number="7.2.9">
<h3><span class="header-section-number">7.2.9</span> Run Script</h3>
<p>Execute custom R scripts using user-created Datalists within iMESc.
Saved Datalists are accessible from the <code>saved_data</code>
object.</p>
<p>Example:</p>
<pre><code>names(saved_data) #Lists the names of the Datalists.
attr(saved_data[[&quot;nema_araca&quot;]],&quot;factors&quot;) #acess the Factor-Attribute, where &#39;nema_araca&#39; is the Datalist name
attr(saved_data[[&quot;nema_araca&quot;]],&quot;coords&quot;) #acess the Coords-Attribute</code></pre>
<p>Modify permanently iMESc objects:</p>
<pre><code>names(vals$saved_data)[1] &lt;- &quot;new name&quot; #Modifies the name of the first Datalist.</code></pre>
</div>
<div id="datalist-manager" class="section level3" number="7.2.10">
<h3><span class="header-section-number">7.2.10</span> Datalist
Manager</h3>
<p>Manage saved Datalists and their attributes. The manager displays the
size of each Datalist, and options for deleting attributes.</p>
</div>
<div id="delete-datalists" class="section level3" number="7.2.11">
<h3><span class="header-section-number">7.2.11</span> Delete
Datalists</h3>
<p>Remove a Datalist entirely.</p>
</div>
</div>
</div>
<div id="filter-observations" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> <img
src="images/filter_obs.png" style="max-width: 44px; max-height: 31px"
width="40" /> Filter observations</h2>
<p>This tool allows manipulating numeric attributes by filtering
observations based on certain criteria. The available options are:</p>
<ul>
<li><p><strong>Individual row selection</strong>: Manually select
observations using Datalist IDs.</p></li>
<li><p><strong>Na.omit</strong>: Remove all rows with any empty (NAs)
cells.</p></li>
<li><p><strong>Remove Zero Variance</strong>: Remove rows with near-zero
variance.</p></li>
<li><p><strong>Match IDs with Datalist</strong>: Constrain the target
Datalist to observations (IDs) from another Datalist.</p></li>
<li><p><strong>Filter by Factors</strong>: Filter observations using a
tree structured by the levels of the Factor-Attribute. You can click on
the nodes to expand and select the factor levels. This function is
available for factors with fewer than 100 levels.</p></li>
</ul>
</div>
<div id="filter-variables" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> <img
src="images/filter_vars.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Filter variables</h2>
<p>This tool allows manipulating the Numeric-Attribute by filtering
variables. The available options for value-based removal are:</p>
<ul>
<li><strong>Individual Selection</strong>: Manually select specific
variables (columns) to keep or remove from the Datalist.</li>
<li><strong>Value-based removal</strong>: Remove numeric variables
contributing less than a specified percentage of the total sum across
all observations. The methods for this option are:
<ul>
<li><strong>Abund&lt;</strong>: Remove variables with a total value less
than x-percent of the total sum across all observations. This is useful
to exclude variables with low overall contribution.</li>
<li><strong>Freq&lt;</strong>: Remove variables that occur in less than
x-percent of the total number of observations. This is helpful when you
want to exclude rarely occurring variables.</li>
<li><strong>Singletons</strong>: Remove variables that occur only once
in the dataset. This option is relevant for counting data and helps
eliminate variables with no meaningful variation.</li>
</ul></li>
<li><strong>Correlation-based removal</strong>: This option uses the
<strong><code>findCorrelation</code></strong> function from the ‘caret’
package. It considers the absolute values of pair-wise correlations
between variables. If two variables have a high correlation, the
function looks at the mean absolute correlation of each variable,
considering the whole data, and removes the variable with the largest
mean absolute correlation. The <strong><code>exact</code></strong>
argument is set to TRUE, meaning that the function re-evaluates the
average correlations at each step.</li>
<li><strong>Remove Zero Variance:</strong> Revove columns with zero
variance.</li>
<li><strong>Remove near Zero Variance:</strong> This option uses the
<code>nearZeroVar</code> function from the <code>caret</code> package.
It identifies and removes near zero variance predictors. Predictors with
near-zero variance have either zero variance (only one unique value) or
very few unique values relative to the number of samples, with a large
frequency ratio between the most common and second most common values.
Removing such predictors can help eliminate features that do not
contribute much information.</li>
</ul>
</div>
<div id="transformations" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> <img
src="images/transfs.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Transformations</h2>
<p>The “Transformations” tool enables preprocessing of the
Numeric-Attribute using various transformation methods.</p>
<div id="transformation" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Transformation</h3>
<p>Provides a wide range of transformation options:</p>
<ol style="list-style-type: decimal">
<li><p><strong>None</strong>: No Transformation. Select this option if
you do not want to apply any transformation to the
Numeric-Attribute.</p></li>
<li><p><strong>Log2</strong>: Logarithmic base 2 transformation as
suggested by Anderson et al. (2006). It follows the formula log_b (x) +
1 for x &gt; 0, where ‘b’ is the base of the logarithm. Zeros are left
as zeros. Higher bases give less weight to quantities and more to
presences, and logbase = Inf gives the presence/absence scaling. Note
that this is not log(x+1).</p></li>
<li><p><strong>Log10</strong>: Logarithmic base 10 transformation as
suggested by Anderson et al. (2006). It follows the formula log_b (x) +
1 for x &gt; 0, where ‘b’ is the base of the logarithm. Zeros are left
as zeros. Higher bases give less weight to quantities and more to
presences, and logbase = Inf gives the presence/absence scaling. Note
that this is not log(x+1).</p></li>
<li><p><strong>Total</strong>: Divide by the line (observation) total.
This transformation scales the values based on the total sum of each
observation.</p></li>
<li><p><strong>Max</strong>: Divide by the column (variable) maximum.
This transformation scales the values based on the maximum value of each
variable.</p></li>
<li><p><strong>Frequency</strong>: Divide by the column (variable) total
and multiply by the number of non-zero items, so that the average of
non-zero entries is one. This transformation scales the values based on
the frequency of occurrence.</p></li>
<li><p><strong>Range</strong>: Standardize column (variable) values into
the range 0 … 1. If all values are constant, they will be transformed to
0. This transformation brings the values to a common scale.</p></li>
<li><p><strong>Pa</strong>: Scale x to presence/absence scale (0/1).
This transformation converts the values to binary (0 for absence, 1 for
presence).</p></li>
<li><p><strong>Chi.square</strong>: Divide by row sums and square root
of column sums and adjust for the square root of the matrix total. This
transformation is relevant for specific statistical analyses.</p></li>
<li><p><strong>Hellinger</strong>: Square root of method = total. This
transformation is used for certain distance calculations.</p>
<p><strong>Sqrt2</strong>: Square root transformation. This
transformation takes the square root of each value.</p></li>
<li><p><strong>Sqrt4</strong>: 4th root transformation. This
transformation takes the 4th root of each value.</p></li>
<li><p><strong>Log2(x+1)</strong>: Logarithmic base 2 transformation
(x+1). This is a variant of the log2 transformation that adds 1 before
taking the logarithm.</p></li>
<li><p><strong>Log10(x+1)</strong>: Logarithmic base 10 transformation
(x+1). This is a variant of the log10 transformation that adds 1 before
taking the logarithm.</p></li>
<li><p><strong>BoxCox</strong>: Designed for non-negative responses.
Boxcox transforms non-normally distributed data to a set of data that
has an approximately normal distribution. The Box-Cox transformation is
a family of power transformations.</p></li>
<li><p><strong>Yeojohson</strong>: Like the Box-Cox model but can
accommodate predictors with zero and/or negative values. This is another
family of power transformations.</p></li>
<li><p><strong>ExpoTrans</strong>: Exponential transformation. This
transformation applies the exponential function to each value.</p></li>
</ol>
</div>
<div id="scale-and-centering" class="section level3" number="7.5.2"
data-link="Scale and Centering">
<h3><span class="header-section-number">7.5.2</span> Scale and
Centering</h3>
<p>This tool uses the function <strong><code>scale</code></strong> from
R base for scaling and centering operations. You have the following
options:</p>
<ul>
<li><p><strong>Scale</strong>: If checked, scaling is done by dividing
the (centered) columns of “x” either by their standard deviations (if
center is TRUE) or by the root mean square (if center is
FALSE).</p></li>
<li><p><strong>Center</strong>: If checked, centering is done by
subtracting the column means (omitting NAs) of “x” from their
corresponding columns</p></li>
</ul>
</div>
</div>
<div id="data-imputation" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> <img
src="images/imput.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Data imputation</h2>
<p>This tool provides methods for completing missing values with values
estimated from the observed data. It is available only for Datalists
that contain missing data either in the Numeric-Attribute or in the
Factor-Attribute. The function <strong><code>preProcess</code></strong>
from the <strong><code>caret</code></strong> package is used for
imputation. To impute missing values, follow these steps:</p>
<ol style="list-style-type: decimal">
<li><p>Choose the Target-Attribute.</p></li>
<li><p>Pick a Method (described below).</p></li>
<li><p>Click the blue “Flash” button. The “Save Changes” dialog will
automatically pop-up.</p></li>
<li><p>Save the Datalist with imputed values as a new Datalist or
replace an existing one.</p></li>
</ol>
<p>Methods for imputation:</p>
<ul>
<li><p><strong>Knn</strong> <code>(caret)</code>: k-nearest neighbor
imputation is only available for the Numeric-Attribute. It is c arried
out by finding the k closest samples (Euclidean distance) in the
dataset. This method automatically centers and scales your
data.</p></li>
<li><p><strong>Bagimpute</strong> <code>(caret)</code>: Only available
for the Numeric-Attribute. Imputation via bagging fits a bagged tree
model for each predictor (as a function of all the others). This method
is simple, more accurate, and accepts missing values, but it has a much
higher computational cost.</p></li>
<li><p><strong>MedianImpute</strong> <code>(caret)</code>: Only
available for the Numeric-Attribute. Imputation via medians takes the
median of each predictor in the training set and uses them to fill
missing values. This method is simple, fast, and accepts missing values
but treats each predictor independently, which may lead to
inaccuracies.</p></li>
<li><p>pmm <code>(mice)</code>: Predictive mean matching (PMM) is
available for both Numeric and Factor Attributes. It involves selecting
observations with the closest predicted values as imputation candidates.
This method maintains the distribution and variability of the data,
making it suitable for data that is normally distributed.</p></li>
<li><p>rf <code>(mice)</code>: Random forest imputation is available for
both Numeric and Categorical-Attributes. It use an ensemble of decision
trees to predict missing values, This non-parametric method can handle
complex interactions and nonlinear relationships but may be
computationally intensive.</p></li>
<li><p>cart <code>(mice)</code>: Classification and regression trees
(CART) imputation is available for both Numeric and
Categorical-Attributes. It is a method that applies decision trees for
imputation. It works by splitting the data into subsets which then
result in a prediction model.</p></li>
</ul>
</div>
<div id="data-partition" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> <img
src="images/split.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Data partition</h2>
<p>Data partitioning is a critical step in evaluating machine learning
models. Creating distinct training and testing sets allows for accurate
assessment of the model’s performance on unseen data, avoiding issues
like overfitting and obtaining more reliable performance metrics. In
iMESc, the Data Partition tool adds a partition as a factor in the
Factor-Attribute. It uses the <code>createDataPartition</code> function
from the caret package. Users can specify the percentage of observations
to be used for the test and choose between the following methods:</p>
<ul>
<li><p><strong>Balanced Sampling:</strong> Ensures balanced
distributions within the splits for classification or regression
models.</p>
<ul>
<li><p>For classification models, random sampling is done within the
levels of the target variable (y) to balance class distributions within
the splits.</p></li>
<li><p>For regression models, samples are divided into sections based on
percentiles of the numeric target variable (Y), with sampling performed
within these subgroups.</p></li>
</ul></li>
<li><p><strong>Random Sampling:</strong> simple random sampling is
used.</p></li>
</ul>
</div>
<div id="aggregate" class="section level2" number="7.8">
<h2><span class="header-section-number">7.8</span> <img
src="images/agg.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Aggregate</h2>
<p>The “Aggregate” tool utilizes the
<strong><code>aggregate</code></strong> function from R base. This
process involves aggregating individual cases of the Numeric-Attribute
based on a grouping factor.</p>
<p>The tool offers various calculation options to aggregate the
data:</p>
<ul>
<li><p><strong>Mean</strong>: Calculates the mean of each group
(selected factor).</p></li>
<li><p><strong>Sum</strong>: Calculates the sum of values for each group
(selected factor).</p></li>
<li><p><strong>Median</strong>: Calculates the median of each group
(selected factor).</p></li>
<li><p><strong>Var</strong>: Calculates the variance of each group
(selected factor).</p></li>
<li><p><strong>SD</strong>: Calculates the standard deviation of each
group (selected factor).</p></li>
<li><p><strong>Min</strong>: Retrieves the minimum value for each group
(selected factor).</p></li>
<li><p><strong>Max</strong>: Retrieves the maximum value for each group
(selected factor).</p></li>
</ul>
</div>
<div id="create-palette" class="section level2 boxtext" number="7.9">
<h2><span class="header-section-number">7.9</span> <img
src="images/palette.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Create Palette</h2>
<div style="padding-left: 20px; display: flex">
<div style="width: 70%">
<p>The “Create Palette” tool utilizes the
<strong><code>colourpicker</code></strong> tool from the
<strong><code>colourpicker</code></strong> package, enabling users to
interactively select colors for their palette. Subsequently, iMESc
employs <strong><code>colorRampPalette</code></strong> to generate
customized color palettes suitable for graphical outputs.</p>
</div>
<div style="width: 40%">
<div class="float">
<img src="gif/create_palette.gif" class="img1"
alt="Gif S7.9 - Create Palette" />
<div class="figcaption">Gif S7.9 - Create Palette</div>
</div>
</div>
</div>
</div>
<div id="savepoint" class="section level2" number="7.10">
<h2><span class="header-section-number">7.10</span> <img
src="images/savepoint.png"
style="border: 1px solid #05668D;max-width: 44px; max-height: 31px"
width="40" /> Savepoint</h2>
<div style="padding-left: 20px; display: flex">
<div style="width: 70%">
<ul>
<li><p><strong>Create</strong>: create a Savepoint, which is a single R
object to be downloaded and that can be reloaded later or shared to
restore workspace.</p></li>
<li><p><strong>Restore</strong> : Upload a Savepoint (.rds file) to
restore the workspace.</p></li>
</ul>
</div>
<div style="width: 50%">
<div class="float">
<img src="images/pre_8.png" alt="Fig. S7.10.1 -" />
<div class="figcaption">Fig. S7.10.1 -</div>
</div>
</div>
</div>
</div>
</div>
<div id="sidebar-menu" class="section level1" number="8">
<h1><span class="header-section-number">8</span> Sidebar-menu</h1>
<div id="data-bank" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> <img
src="images/side1_databank.png"
style="max-width: 54px; max-height: 30px" width="40" /> Data Bank</h2>
<p>The Data Bank module is designed for data visualization and
downloading purposes. It uses the <code>DT</code> package to render
sheets with interactive tables. When using the Numeric or
Factor-Attribute buttons, users can edit the cells of their sheets.<span
class="empha">However, it’s important to use it with caution, as the
changes made are instantaneously applied and cannot be
undone.</span></p>
<p>The available buttons in the Data Bank are as follows:</p>
<p><img src="images/a1.png" style="max-width: 54px; max-height: 30px"
width="54" /> <strong>Numeric-Attribute:</strong> Shows the sheet for
the Numeric-Attribute data.</p>
<p><img src="images/a2.png" style="max-width: 54px; max-height: 30px"
width="54" /> <strong>Factor-Attribute:</strong> Displays the sheet for
the Factor-Attribute data.</p>
<p><img src="images/a3.png" style="max-width: 54px; max-height: 30px"
width="54" /> <strong>Coords-Attribute:</strong> Shows the sheet for the
Coords-Attribute data.</p>
<p><img src="images/a4.png" style="max-width: 54px; max-height: 30px"
width="54" /> <strong>Shapes</strong> (if any)<strong>:</strong></p>
<ul>
<li><p><span id="Base-Shape"><em>Base-Shape:</em></span> plot the
base_shape</p></li>
<li><p><em>Layer-Shape:</em> plot the Layer-Shape</p></li>
<li><p><em>Extra-Shapes:</em> plot the Extra-Shapes</p></li>
</ul>
<p>Additional buttons will appear dynamically based on the presence of
saved models in the target Datalist:</p>
<p><img src="images/a5.png" style="max-width: 54px; max-height: 30px"
width="54" /> <strong>SOM-Attribute:</strong> displays the summary of
SOM models (<a href="#self-organizing-maps">unsupervised</a> and <a
href="#self-organizing-maps-1">supervised</a>) (if saved in the target
Datalist).</p>
<p><img src="images/sup-icon.png" style="max- max-" width="54" />
<strong>Supervised Models-Attribute:</strong> Displays the summary of
supervised models (if saved in the target Datalist) in two tabs:
“Classification Models” and “Regression Models”.</p>
<p><img src="images/comments-icon.png" style="max- max-" width="54" />
<strong>Comments:</strong>: Create/edit comments for specified
Datalists.</p>
</div>
<div id="descriptive-tools" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> <img
src="images/side2_desc.png" style="max-width: 54px; max-height: 30px"
width="40" /> Descriptive tools</h2>
<p>This module provides multiple tabs for descriptive analysis and
visualization of the data.</p>
<div class="float">
<video src="images/t7-desctools.mp4" style="width: 600px;height: auto"
width="400" controls=""><a href="images/t7-desctools.mp4">Video S8.2 -
Descriptive tools tutorial</a></video>
<div class="figcaption">Video S8.2 - Descriptive tools tutorial</div>
</div>
<div id="summary" class="section level3" number="8.2.1">
<h3><span class="header-section-number">8.2.1</span> Summary</h3>
<p>The Summary tab consists of three subtabs:</p>
<ol style="list-style-type: decimal">
<li><p>Datalist: Shows the structure of the Datalist.</p></li>
<li><p>Numeric-Attribute: a summary view of the numeric variables,
displaying histograms and quantile distributions for each
variable.</p></li>
<li><p>Factor-Attribute: a summary view of the factors, displaying a
plot with factors and the number of observations for each
level.</p></li>
</ol>
</div>
<div id="ridges" class="section level3" number="8.2.2">
<h3><span class="header-section-number">8.2.2</span> Ridges</h3>
<p>This functionality plots the Numeric-Attribute as ridges lines
grouped by a Factor.</p>
<p>Ridge plots are partially overlapping line plots that create the
impression of a mountain range. They are useful for visualizing changes
in distributions over a gradient. This function uses the <a
href="https://rdrr.io/cran/ggridges/man/geom_ridgeline.html">geom_ridgeline</a>
function from the <a href="https://rdrr.io/cran/ggridges/">ggridges</a>
package.</p>
</div>
<div id="pairplot" class="section level3" number="8.2.3">
<h3><span class="header-section-number">8.2.3</span> Pairplot</h3>
<p>The pair plot feature in iMESc utilizes the <code>ggpairs</code>
function from the <code>GGally</code> package to create a matrix of
plots based on selected variables from the Numeric-Attribute, and
optionally one additional categorical variable from the Factor-Attribute
to group the ridges.</p>
<p>In a pair plot, each variable is plotted against all other variables
in the dataset, resulting in a matrix of scatterplots showing the
relationship between each pair of variables.</p>
<p>Users have the flexibility to customize the display in each panel
according to their preferences:</p>
<ul>
<li><p>Upper Panel: Users can opt to display correlations or
correlations per group or none.</p></li>
<li><p>Lower Panel: Options include displaying points, points colored
per group, or no points at all.</p></li>
<li><p>Diagonal Panel: Users can choose from several options, such as
Density, Density per group, Histogram, Histogram per group, or
none.</p></li>
</ul>
</div>
<div id="boxplot" class="section level3" number="8.2.4">
<h3><span class="header-section-number">8.2.4</span> Boxplot</h3>
<ul>
<li>The Box Plot tab allows users to create boxplots with numerous
graphical options.</li>
</ul>
</div>
<div id="correlation-plot" class="section level3" number="8.2.5">
<h3><span class="header-section-number">8.2.5</span> Correlation
plot</h3>
<ul>
<li>The Correlation Plot tab uses the <code>heatmap.2</code> function
from <code>gplots</code> package. Users can choose the correlation
method (e.g., Pearson, Spearman) and filter correlations based on a
cutoff value (filtering done using the findCorrelation function from
caret). All arguments available in this function are accessible in
iMESc. For a detailed description of all arguments, users can refer to
the documentation of the <code>heatmap.2</code> function.<br />
</li>
</ul>
</div>
<div id="mds" class="section level3" number="8.2.6">
<h3><span class="header-section-number">8.2.6</span> MDS</h3>
<ul>
<li>The MDS (Nonmetric Multidimensional Scaling) tab uses the <a
href="https://rdrr.io/rforge/vegan/man/metaMDS.html">metaMDS</a>
function from the <a href="https://rdrr.io/rforge/vegan/">vegan</a>
package. It uses default arguments, with user options to choose the
distance metric (e.g., Bray-Curtis, Euclidean, Jacquard). Users can
interact with various graphical options, including coloring observations
by a factor from the associated Factor-Attribute.</li>
</ul>
</div>
<div id="pca" class="section level3" number="8.2.7">
<h3><span class="header-section-number">8.2.7</span> PCA</h3>
<ul>
<li>The PCA tab utilizes the <a
href="https://www.rdocumentation.org/packages/stats/versions/3.6.2/topics/prcomp">prcomp</a>
function from R base. We recommend scaling the data before conducting
PCA analysis. Users can interact with several graphical options,
including coloring observations by a factor from the associated
Factor-Attribute.</li>
</ul>
</div>
<div id="rda" class="section level3" number="8.2.8">
<h3><span class="header-section-number">8.2.8</span> RDA</h3>
<p>The RDA tab employs the <a
href="https://www.rdocumentation.org/packages/vegan/versions/2.4-2/topics/cca">rda</a>
function from the <a href="https://rdrr.io/rforge/vegan/">vegan</a>
package. It requires at least two Datalists to build a Y~X model. The
results are presented in two panels:</p>
<ul>
<li><p><strong>Plot</strong>: Offers several graphical options,
including coloring observations by a factor from the associated
Factor-Attribute.</p></li>
<li><p><strong>Summary</strong>: Provides results of the rda model, such
as variable importance (constrained and unconstrained), variable and
observation scores, linear constraints, and biplot.</p></li>
</ul>
</div>
<div id="segrda" class="section level3" number="8.2.9">
<h3><span class="header-section-number">8.2.9</span> segRDA</h3>
<p>The segRDA tab implements the <a
href="https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210x.13300">segRDA</a>
workflow (Vieira et al., 2019) for modeling non-continuous linear
responses of ecological data. The routine consists of three panels:</p>
<ul>
<li><p><strong>SMW</strong>: Split Moving Windows along ordered
data.</p></li>
<li><p><strong>DP</strong>: Dissimilarity Profile of the SMW results for
identifying breakpoints.</p></li>
<li><p><strong>pwRDA</strong>: Performs a piece-wise redundancy analysis
using specified breakpoints. The results are presented in the same way
as in the RDA panel.</p></li>
</ul>
</div>
</div>
<div id="spatial-tools" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> <img
src="images/side3_map.png" style="max-width: 54px; max-height: 30px"
width="40" /> Spatial Tools</h2>
<div class="float">
<video src="images/t6-maps.mp4" style="width: 600px;height: auto"
controls=""><a href="images/t6-maps.mp4">Video S8.3 - Spatial tools
tutorial</a></video>
<div class="figcaption">Video S8.3 - Spatial tools tutorial</div>
</div>
<div id="spatial-tools-module" class="section level3" number="8.3.1">
<h3><span class="header-section-number">8.3.1</span> Spatial Tools
Module</h3>
<p>The Spatial Tools module is designed for spatialization and requires
the Coords-Attributes attached to the chosen Datalist. This module
offers different spatial representations through seven tabs. Across all
spatial representations, the user can specify the target variable
(Numeric or Factor-Attribute), filter observations corresponding to
specific factor levels, customize color palettes, define break points,
display text labels (sourced from Factor-Attribute columns), and include
base shape and layer shapes.</p>
</div>
<div id="spatial-representations" class="section level3" number="8.3.2">
<h3><span class="header-section-number">8.3.2</span> Spatial
Representations</h3>
<table style="width:100%;">
<colgroup>
<col width="3%" />
<col width="3%" />
<col width="92%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Tab</strong></th>
<th><strong>Plot Engineers</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Circles</strong></td>
<td>leaflet, ggplot2</td>
<td>Displays Numeric-Attribute variables as circles that can vary in
size and color based on the data values. For Factor-Attribute, circles
maintain a uniform size.</td>
</tr>
<tr class="even">
<td><strong>Pies</strong></td>
<td>leaflet, ggplot2</td>
<td>Uses a selected factor to categorize and aggregate target data
within a buffer zone. This aggregation is visually represented through
pie charts on the map, where each pie chart corresponds to a buffer zone
and displays the summarized data by factor levels. The buffer utilizes
the geodist package to calculate geodesic distances between each pair of
coordinates from the target data, defining a circular buffer zone around
each point with a radius equal to the specified distance.</td>
</tr>
<tr class="odd">
<td><strong>Raster</strong></td>
<td>leaflet, ggplot2</td>
<td>The raster map option performs simple rasterization at the
coordinate’s resolution.</td>
</tr>
<tr class="even">
<td><strong>Interpolation</strong></td>
<td>leaflet, ggplot2</td>
<td>This approach interpolates variables/factors using different models.
Kriging uses variograms to model the spatial correlation between data
points (gstat package). Inverse Distance Weighting (IDW) assigns weights
inversely proportional to the distance between sample points and the
interpolation point (gstat package). K-Nearest Neighbors (KNN) estimates
the value of an unknown point based on the values of the k nearest
neighbors in feature space. SVM and Gaussian Process models are also
supported.</td>
</tr>
<tr class="odd">
<td>Surface (3D)*</td>
<td>plotly, plot3D</td>
<td>The Surface option draws a perspective plot of a surface over the
coordinates plane. The surface passes through the Z values corresponding
to all pairs of coordinates. Additionally, the surface can be colored
based on a selected factor (4D).</td>
</tr>
<tr class="even">
<td>Stack (3D)*</td>
<td>plotly, plot3D</td>
<td>Stack allows the combination of multiple
discrete/interpolated/rasterized planes (for a common geographic area)
to represent an integrated map. The saved maps act as layers in the
stack, and their position along the Z-axis can be defined by the
user.</td>
</tr>
</tbody>
</table>
<p>*<em>Requires at least one saved raster from the Raster or
Interpolation tabs.</em></p>
</div>
<div id="plot-engineers" class="section level3" number="8.3.3">
<h3><span class="header-section-number">8.3.3</span> Plot Engineers</h3>
<ul>
<li><p><strong>Leaflet:</strong> Provides interactive maps with
automatic spatial context management, reducing the need for manual input
of base and layer shapes and simplifying spatial setup. However, its
drawback is the restriction to downloading maps only as
snapshots.</p></li>
<li><p><strong>ggplot2:</strong> Offers broad customization options and
high-quality download capabilities, though it requires users to manually
incorporate base maps or additional shape layers for spatial data
contextualization.</p></li>
<li><p><strong>Plotly:</strong> Interactive visualization with extensive
capabilities for customizing and manipulating plots in 3D.</p></li>
<li><p><strong>plot3D:</strong> Uses the plot3D package and its function
persp3D, rendering the plot through Graphics from base.</p></li>
</ul>
</div>
<div id="interpolation-tunning" class="section level3" number="8.3.4">
<h3><span class="header-section-number">8.3.4</span> Interpolation
tunning</h3>
<table style="width:100%;">
<colgroup>
<col width="6%" />
<col width="16%" />
<col width="76%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Model</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>Model type</code></td>
<td>Kriging</td>
<td>All models from <code>gstat::vgm()</code> are available:
exponential, spherical, Gaussian, exponential class/stable, Matern,
Matern, M. Stein’s parameterization, circular, linear, bessel,
pentaspherical, periodic, wave, hole, logarithmic, power, spline, and
Legendre.</td>
</tr>
<tr class="even">
<td><code>Variogram autofit</code></td>
<td>Kriging</td>
<td>iMESc uses the <code>autofitVariogram</code> function from the
<code>automap</code> package to automatically fit an experimental
variogram.</td>
</tr>
<tr class="odd">
<td><code>Sill</code></td>
<td>Kriging</td>
<td>Estimated as the mean of the max and the median of the
semi-variance.</td>
</tr>
<tr class="even">
<td><code>Range</code></td>
<td>Kriging</td>
<td>Defined as 0.10 times the diagonal of the bounding box of the
data.</td>
</tr>
<tr class="odd">
<td><code>Nugget</code></td>
<td>Kriging</td>
<td>Defined as the min of the semi-variance.</td>
</tr>
<tr class="even">
<td><code>K-Folds</code></td>
<td>Kriging, svmRadial, gaussprRadial, svmRadialCost</td>
<td>The number of folds for cross-validation.</td>
</tr>
<tr class="odd">
<td><code>Resolution</code></td>
<td>Kriging, IDW, svmRadial, gaussprRadial, svmRadialCost</td>
<td>Resolution of the grid for interpolation.</td>
</tr>
<tr class="even">
<td><code>nmax</code></td>
<td>IDW</td>
<td>Specifies the number of nearest observations used for a kriging
prediction or simulation. If empty (default), all observations are
used.</td>
</tr>
<tr class="odd">
<td><code>nmin</code></td>
<td>IDW</td>
<td>If the number of nearest observations within a distance
<code>maxdist</code> is less than <code>nmin</code>, a missing value is
generated.</td>
</tr>
<tr class="even">
<td><code>omax</code></td>
<td>IDW</td>
<td>Maximum number of observations to select per quadrant; relevant if
<code>maxdist</code> has been defined.</td>
</tr>
<tr class="odd">
<td><code>maxdist</code></td>
<td>IDW</td>
<td>Only observations within this distance from the prediction location
are used for prediction or simulation.</td>
</tr>
<tr class="even">
<td><code>k</code></td>
<td>KNN</td>
<td>The number of neighbors considered for KNN interpolation.</td>
</tr>
<tr class="odd">
<td><code>Tune Length</code></td>
<td>svmRadial, gaussprRadial, svmRadialCost</td>
<td>Granularity in the tuning parameter (sigma for gaussprRadial and
svmRadial, Cost for svmRadial and svmRadialCost).</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="biodiversity-tools" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> <img
src="images/side4_bio.png" style="max-width: 54px; max-height: 30px"
width="40" /> Biodiversity Tools</h2>
<div class="float">
<video src="images/t14-Divtools.mp4" style="width: 600px;height: auto"
width="400" controls=""><a href="images/t14-Divtools.mp4">Video S8.5.1 -
Diversity tools tutorial</a></video>
<div class="figcaption">Video S8.5.1 - Diversity tools tutorial</div>
</div>
<p>The Biodiversity Tools module provides a collection of classic
ecological diversity metrics. These metrics are widely used to quantify
the biological diversity of a specific area or dataset.</p>
<p>To use the Biodiversity Tools, the user selects a target Datalist
containing the necessary data. The module then computes the selected
diversity metrics from the Numeric_Attribute and generates a dataframe
with the calculated results. The user has the option to save the results
as a new Datalist, which will retain the Factor, Coords, and
Shapes-Attributes from the target Datalist.</p>
<div id="biological-diversity-indexes" class="section level3"
number="8.4.1">
<h3><span class="header-section-number">8.4.1</span> Biological
Diversity Indexes</h3>
<div class="small_table">
<table style="width:99%;">
<colgroup>
<col width="2%" />
<col width="5%" />
<col width="34%" />
<col width="35%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Abrev</strong></th>
<th><strong>Index</strong></th>
<th><strong>Description</strong></th>
<th><strong>Formula</strong></th>
<th><strong>Formula Terms</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>N</td>
<td>Abundance</td>
<td>Total number of individuals in a community.</td>
<td></td>
<td></td>
</tr>
<tr class="even">
<td>S</td>
<td>Species Richness (S)</td>
<td>Total number of species in each observation.</td>
<td></td>
<td></td>
</tr>
<tr class="odd">
<td>margalef</td>
<td>Margalef Index</td>
<td>Measures the total number of species weighted by the logarithm of
the total number of individuals.</td>
<td><span class="math display">\[ \text{Margalef} = \frac{S - 1}{\ln N}
\]</span></td>
<td><span class="math inline">\(S\)</span>: Total number of species;
<span class="math inline">\(N\)</span>: Total number of individuals</td>
</tr>
<tr class="even">
<td>D</td>
<td>Simpson Diversity (D)</td>
<td>The probability that two individuals drawn at random from an
infinite community would belong to the same species.</td>
<td><span class="math display">\[ D = \sum p_i^2 \]</span></td>
<td><span class="math inline">\(p_i\)</span>: Proportion of individuals
in species <span class="math inline">\(i\)</span></td>
</tr>
<tr class="odd">
<td>H</td>
<td>Shannon Diversity (H)</td>
<td>Considers both species richness and evenness, measuring uncertainty
or entropy in the community.</td>
<td><span class="math display">\[ H = -\sum (p_i \cdot \ln p_i)
\]</span></td>
<td><span class="math inline">\(p_i\)</span>: Proportion of individuals
in species <span class="math inline">\(i\)</span></td>
</tr>
<tr class="even">
<td>H<sub>log2</sub></td>
<td>Shannon Function (Base 2)</td>
<td>Shannon index calculated with base 2 logarithm.</td>
<td><span class="math display">\[ H_{\text{log}_2} = -\sum (p_i \cdot
\log_2 p_i) \]</span></td>
<td><span class="math inline">\(p_i\)</span>: Proportion of individuals
in species <span class="math inline">\(i\)</span></td>
</tr>
<tr class="odd">
<td>H<sub>log10</sub></td>
<td>Shannon Function (Base 10)</td>
<td>Shannon index calculated with base 10 logarithm.</td>
<td><span class="math display">\[ H_{\text{log}_{10}} = -\sum (p_i \cdot
\log_{10} p_i) \]</span></td>
<td><span class="math inline">\(p_i\)</span>: Proportion of individuals
in species <span class="math inline">\(i\)</span></td>
</tr>
<tr class="even">
<td>J</td>
<td>Evenness (J)</td>
<td>Measure of how different the abundances of species in a community
are from each other. The Shannon evenness is calculated as the ratio of
Shannon diversity to the maximum possible diversity.</td>
<td><span class="math display">\[ J = \frac{H}{\ln(S)} \]</span></td>
<td><span class="math inline">\(H\)</span>: Shannon diversity index;
<span class="math inline">\(S\)</span>: Total number of species</td>
</tr>
<tr class="odd">
<td>DOM<sub>rel</sub></td>
<td>Relative Dominance (Dom<sub>rel</sub>)</td>
<td>A simple measure of dominance where the abundance of the most
abundant species is divided by the total abundance.</td>
<td><span class="math display">\[ \text{Dom}_{\text{rel}} =
\frac{N_1}{N} \]</span></td>
<td><span class="math inline">\(N_1\)</span>: Abundance of the most
abundant species; <span class="math inline">\(N\)</span>: Total
abundance</td>
</tr>
<tr class="even">
<td>Log<sub>skew</sub></td>
<td>Skewness (Log Scale)</td>
<td>Measures the asymmetry of the abundance distribution on a log scale.
Positive skew indicates more probability on the right (abundant side),
negative skew indicates more on the left side.</td>
<td><span class="math display">\[ \text{LogSkew} = \frac{\sum
\left(\frac{\left(\log(n_i) - \mu\right)^3}{S}\right)}{\left[\sum
\left(\frac{\left(\log(n_i) - \mu\right)^2}{S}\right)\right]^{3/2} \cdot
\sqrt{\frac{S - 1}{S}}} \]</span></td>
<td><span class="math inline">\(n_i\)</span>: Abundance of species <span
class="math inline">\(i\)</span>; <span
class="math inline">\(\mu\)</span>: Mean of log abundance; <span
class="math inline">\(S\)</span>: Number of species</td>
</tr>
<tr class="odd">
<td>Chao1</td>
<td>Chao1 Index</td>
<td>An estimate of species richness that adjusts for rare species.
Accepts only integer counts.</td>
<td><span class="math display">\[ \hat{S} = S_{\text{obs}} +
\frac{F_1^2}{2F_2} \]</span></td>
<td><span class="math inline">\(S_{\text{obs}}\)</span>: Number of
observed species; <span class="math inline">\(F_1\)</span>: Number of
species observed once; <span class="math inline">\(F_2\)</span>: Number
of species observed twice</td>
</tr>
<tr class="even">
<td>Fisher</td>
<td>Fisher’s Alpha</td>
<td>An index that estimates species richness based on the number of rare
species. The formula is based on the Fisher’s log series
distribution.</td>
<td><span class="math display">\[ \text{Fisher&#39;s \, Alpha} =
\frac{S}{\ln\left(\frac{N}{N - F_1}\right)} \]</span></td>
<td><span class="math inline">\(S\)</span>: Total number of species;
<span class="math inline">\(N\)</span>: Total number of individuals;
<span class="math inline">\(F_1\)</span>: Number of species observed
once</td>
</tr>
<tr class="odd">
<td>BP</td>
<td>Berger-Parker Index</td>
<td>Measures the proportion of the most abundant species relative to the
total number of individuals.</td>
<td><span class="math display">\[ \text{BP} = \frac{N_1}{N}
\]</span></td>
<td><span class="math inline">\(N_1\)</span>: Abundance of the most
abundant species; <span class="math inline">\(N\)</span>: Total
abundance</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="niche-analysis" class="section level3" number="8.4.2">
<h3><span class="header-section-number">8.4.2</span> Niche Analysis</h3>
<p>The Niche Analysis is performed using the <code>niche</code> function
from the <code>ade4</code> package (Dray and Dufour, 2007). It involves
running a Principal Component Analysis (PCA) on the environmental table
and associating the resulting table of row profiles with the
corresponding faunistic table. This association provides the average
position (i.e., niche position) of each species along the ordination
axes, allowing users to understand the ecological niche of each species
in relation to the environmental factors.</p>
<p>The analysis also includes the Optimal Niche Position (OMI) analysis,
which provides additional insights into the species’ niches. It
calculates the niche breadth value, representing the total variance of
the environmental table weighted by the species’ abundances. This
information helps users understand the range of conditions under which
each species thrives.</p>
<p>Moreover, iMESc enables the extraction of the niche position (NP),
environmental boundaries (EBs), and niche breadths (NBs) of species
along the principal components (Vieira et al., 2019). This detailed
analysis allows for a deeper understanding of how species interact with
the environment and their ecological preferences.</p>
<p>For more in-depth information about the calculation of niche
parameters, users can refer to the work of Dolédec et al. (2000). The
Niche Analysis is a valuable tool for ecologists and environmental
scientists to study species-environment relationships and gain valuable
insights into species distributions and their ecological roles within a
given ecosystem.</p>
</div>
</div>
<div id="unsupervised-algorithms" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> <img
src="images/side5_unsup.png" style="max-width: 54px; max-height: 30px"
width="40" /> Unsupervised Algorithms</h2>
<div id="self-organizing-maps" class="section level3" number="8.5.1">
<h3><span class="header-section-number">8.5.1</span> <img
src="images/side6_som.png" style="max-width: 54px; max-height: 30px"
width="40" /> Self-Organizing maps</h3>
<div class="float">
<video src="images/t9-self-organizing-maps.mp4"
style="width: 600px;height: auto" width="400" controls=""><a
href="images/t9-self-organizing-maps.mp4">Video S8.5.1 - Self-Organizing
maps tutorial</a></video>
<div class="figcaption">Video S8.5.1 - Self-Organizing maps
tutorial</div>
</div>
<p>The Self-Organizing Maps (SOM) module in iMESc offers users powerful
functionality to perform Self-Organizing Maps analysis on their target
Datalists. This analysis is implemented using the
<strong><code>supersom</code></strong> function from the
<strong><code>kohonen</code></strong> R package. By default, the method
trains a single layer, but users can train multiple layers by activating
the “supersom” button and fine-tune the distance for each layer, as well
as adjust the weights for each layer. The SOM module is conveniently
organized into three panels: Training, Results, and Predict, providing
an intuitive and efficient workflow for analyzing and visualizing
data.</p>
<p>Users can specify the grid of units, with options for size and
topology. The app provides automatic suggestions for the grid size
(xdim, ydim) based on a suggested topology. Users can set the following
parameters:</p>
<ul>
<li><p><strong>xdim, ydim</strong>: Dimensions of the grid.</p></li>
<li><p><strong>topo</strong>: Choice between hexagonal or rectangular
topology.</p></li>
<li><p><strong>neighbourhood.fct</strong>: Choice between bubble and
Gaussian neighbourhoods when training a SOM.</p></li>
<li><p><strong>toroidal</strong>: Whether the grid is toroidal or
not.</p></li>
</ul>
<p>For training the SOM, users need to set various parameters:</p>
<ul>
<li><p><strong>dist.fcts</strong>: Determines the distance measure
between each neuron and the input data.</p></li>
<li><p><strong>rlen</strong>: Number of times the complete dataset will
be presented to the network during training.</p></li>
<li><p><strong>seed</strong>: Ensures reproducibility of results when
starting with the same seed value.</p></li>
<li><p><strong>Fine tuning</strong>:</p>
<ul>
<li><p><strong>a1, a2</strong>: Learning rates that indicate the amount
of change during training. Default values decline linearly from 0.05 to
0.01 over rlen updates. These parameters are not used for the batch
algorithm.</p></li>
<li><p><strong>r1, r2</strong>: Radius of the neighborhood, specified as
a single number or a vector (start, stop). If given as a single number,
the radius changes linearly from its initial value to zero. When the
neighborhood becomes smaller than one, only the winning unit is
updated.</p></li>
</ul></li>
<li><p><strong>mode</strong>: Defines the type of learning algorithm to
be used for training the SOM.</p></li>
<li><p><strong>maxNA.fraction</strong>: Maximal fraction of missing (NA)
values allowed in the data to prevent the removal of rows with missing
data.</p></li>
</ul>
<div id="suggested-topology" class="section level4 unnumbered">
<h4 class="unnumbered">Suggested topology*</h4>
<p>Checkbox to automatically calculate the number of map nodes and the
side length ratio as follows (Vesanto, 2000 ):</p>
<ol style="list-style-type: decimal">
<li><p>Determine the number of map nodes using the heuristic
recommendation, <span class="math display">\[
M=5\sqrt{N}
\]</span>where N is the number of observations in the input data set (
Vesanto, 2000 )</p></li>
<li><p>Determine the eigenvectors and eigenvalues in the data from the
autocorrelation matrix</p></li>
<li><p>Set the ratio between the two sides of the grid equivalent to the
ratio between the two largest eigenvalues, and</p></li>
<li><p>Scale the side lengths so that their product (xdim * ydim) is as
close as possible to the number of map units determined above.</p></li>
</ol>
</div>
<div id="results" class="section level4" number="8.5.1.1">
<h4><span class="header-section-number">8.5.1.1</span> <span
id="som_results" class="unnumbered">2. Results</span></h4>
<table>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>2.1. Parameters</strong></td>
<td>In this tab, users can access quality measures and training
parameters, with the option to create a Datalist using the codebook
results for further analysis. They can also download the codebook
results as CSV or XLSX files. Additionally, the trained model can be
downloaded as an .rds file for future reference and usage in R.</td>
</tr>
<tr class="even">
<td><strong>2.2. Changes &amp; Couting</strong></td>
<td><p>This section displays two plots:</p>
<ul>
<li><p><strong>Changes Panel</strong>: Represents the mean distance to
the closest codebook vector during the training process.</p></li>
<li><p><strong>Counting Plot</strong>: Shows the number of objects
mapped to individual units on the SOM.</p></li>
</ul></td>
</tr>
<tr class="odd">
<td><strong>2.3. BMUs</strong></td>
<td><p>In the BMUs tab, users can examine the mapping of observations on
the SOM with various graphical options for customization. Users can
specify the background type as:</p>
<ul>
<li><p><strong>None</strong>: Solid color background.</p></li>
<li><p><strong>U-Matrix</strong>: Highlights units near class boundaries
with higher average distances to their neighbors.</p></li>
<li><p><strong>Property</strong>: Depicts unit properties in color code,
offering insights into variable similarity across units.</p></li>
</ul>
<p>The tab also presents a <a href="#variable-factor-map">Variable
factor map*</a>, illustrating the influence of variables on the units’
locations and clustering. Users can visualize the relative weight of
selected variables through the Variable Pies option.</p></td>
</tr>
<tr class="even">
<td><strong>3.4. Network plot</strong></td>
<td>The Network Plot tab enables users to recreate the training process
at predetermined steps, offering an animated visualization of the
positions of trained neurons, with vertices representing the distance
between neighbors.</td>
</tr>
</tbody>
</table>
</div>
<div id="quality-measures" class="section level4 unnumbered">
<h4 class="unnumbered">Quality measures*</h4>
<p>Metrics calculated using the <code>aweSOM</code> package (Boelaert
J., et. al, 2022).</p>
<table>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>Quantization error</strong></td>
<td>Average squared distance between the data points and the map
prototypes to which they are mapped. Lower is better.</td>
</tr>
<tr class="even">
<td><strong>Percentage of explained variance</strong></td>
<td>Similar to other clustering methods, the share of total variance
that is explained by the clustering (equal to 1 minus the ratio of
quantization error to total variance). Higher is better.</td>
</tr>
<tr class="odd">
<td><strong>Topographic error</strong></td>
<td>Measures how well the topographic structure of the data is preserved
on the map. It is computed as the share of observations for which the
best-matching node is not a neighbor of the second-best matching node on
the map. Lower is better: 0 indicates excellent topographic
representation (all best and second-best matching nodes are neighbors),
1 is the maximum error (best and second-best nodes are never
neighbors).</td>
</tr>
<tr class="even">
<td><strong>Kaski-Lagus error</strong></td>
<td>Combines aspects of the quantization and topographic error. It is
the sum of the mean distance between points and their best-matching
prototypes, and of the mean geodesic distance (pairwise prototype
distances following the SOM grid) between the points and their
second-best matching prototype.</td>
</tr>
<tr class="odd">
<td><strong>Neuron Utilization</strong></td>
<td>The percentage of neurons that are not BMU of any observation</td>
</tr>
</tbody>
</table>
</div>
<div id="variable-factor-map" class="section level4 unnumbered">
<h4 class="unnumbered">Variable factor map*</h4>
<p>The Variable Factor Map (VFM) is a chart that closely resembles the
variable factor map obtained from Principal Component Analysis
(PCA).</p>
<p>To generate the VFM, the weighted correlation for each variable is
computed using the coordinates (x, y) of the neurons and their
corresponding weights (number of instances). The codebook vectors of SOM
cells represent estimations of the conditional averages. Calculating the
variance for each variable allows for the estimation of the between-node
variance of that variable, thus determining its relevance within the
SOM.</p>
<p>When creating the VFM, users have two options based on the
<code>npic</code> parameter (number of variables to display):</p>
<ol style="list-style-type: decimal">
<li><p><strong><code>Most Important Correlations</code></strong><code>:</code>
This option returns the <code>npic</code> variables with the highest
variance. For example, if <code>npic</code> is set to 5, the VFM will
display the top 5 variables with the highest variance or correlation,
depending on the chosen option. These variables are considered the most
influential in explaining the variability within the data on the
SOM.</p></li>
<li><p><strong><code>Clock-wise Correlations</code></strong><code>:</code>
This option also returns the “npic” variables with the highest
correlation when considering the different directions of the codebook.
By analyzing correlations along various directions, it helps identify
variables that exhibit strong correlations with specific orientations on
the SOM.</p></li>
</ol>
</div>
<div id="variable-pies" class="section level4 unnumbered">
<h4 class="unnumbered">Variable pies</h4>
<p>The Variable Pies feature allows users to visualize variables through
pie charts along the SOM units. Users can choose from three options to
display the variables:</p>
<ul>
<li><strong>Top Importance</strong><br />
Variables are displayed based on their importance, determined by the
codebook weights for each neuron. The relative importance scores for
each variable are calculated by normalizing the codebook weights by the
sum of weights for each neuron. The top variables with the highest sum
of relative importance scores across all neurons are identified and
visualized using pie charts representing their weights in the
codebook.</li>
</ul>
<!-- -->
<ul>
<li><p><strong>Top Weight</strong><br />
This option displays variables based on their absolute importance,
determined by the sum of codebook weights for each variable across all
neurons. The top variables with the highest absolute weights are
identified and shown using pie charts that represent their weights in
the codebook.</p></li>
<li><p><strong>Manual</strong><br />
Users can manually select which variables to display in the pie
charts.</p></li>
</ul>
</div>
<div id="predict" class="section level4 unnumbered">
<h4 class="unnumbered">3. Predict</h4>
<p>This tab is intended to generate predictions based on either the
Training Datalist, a New Datalist, or a Partition (data not used in the
training).</p>
<table>
<colgroup>
<col width="62%" />
<col width="37%" />
</colgroup>
<tbody>
<tr class="odd">
<td><p><strong>3.1 Results:</strong></p>
<p>This section displays several prediction results, which can be
downloaded as .csv or .xlsx files. For the option “Codebook and New data
(X),” it is also possible to create a Datalist from these
results.</p></td>
<td><ul>
<li><p><strong>Best-Matching Units:</strong> Shows unit numbers to which
new data observations were mapped.</p></li>
<li><p><strong>Data:</strong> Presents predicted values for the training
data.</p></li>
<li><p><strong>Codebook:</strong> Provides prediction values associated
with map units.</p></li>
</ul></td>
</tr>
<tr class="even">
<td><p><strong>3.2. Performance</strong></p>
<p>In this tab, various performance metrics are available, including
Root-mean square (RMSE), R-squared, and Mean Absolute Error (MAE).
Options include:</p></td>
<td><p>Overall Performance: uses all the observations and variables in
the dataset.</p>
<p>Performance by Observation: evaluates the predictive performance on a
per-observation basis.</p>
<p>Performance by Variable: assesses the predictive performance for each
variable (feature) in the Datalist being predicted.</p></td>
</tr>
<tr class="odd">
<td><div class="cmap">
<p><strong>3.2. BMUs</strong></p>
</div></td>
<td><div class="cmap">
<p>Similar to the <a href="#bmu_plot">BMU plot</a> in section <a
href="#som_results">2.4</a> this section maps the prediction
results.</p>
</div></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="hierarchical-clustering" class="section level3" number="8.5.2">
<h3><span class="header-section-number">8.5.2</span> <img
src="images/side7_hc.png" style="max-width: 54px; max-height: 30px"
width="40" /> Hierarchical clustering</h3>
<div class="float">
<video src="images/t11-HC.mp4" style="width: 600px;height: auto"
width="400" controls=""><a href="images/t11-HC.mp4">Video S8.5.2 -
Hierarchical Clustering tutorial</a></video>
<div class="figcaption">Video S8.5.2 - Hierarchical Clustering
tutorial</div>
</div>
<p>Hierarchical Clustering (HC) analysis is performed on either the
Numeric-Attribute data or the SOM-codebook (if a SOM model has been
saved). The process begins by assigning each object to its own cluster
and then interactively merges the two most similar clusters until only
one cluster remains. During each stage, the distances between clusters
are recalculated using the Lance-Williams dissimilarity update formula,
which is dependent on the chosen clustering method.</p>
<p>iMESc uses the <code>hcut</code> function from the
<code>factoextra</code> package for HC analysis. Users can select the
clustering method that best suits their needs. HC analysis can be
applied to either the Numeric-Attribute data or the codebook obtained
from a saved SOM model. Cluster resulted from HC analysis can be ordered
by a selected Datalist and numeric columns, taking the mean value of
these columns by cluster to reorder the cluster levels.</p>
<p>The clusters can be saved using the flashing blue button found in
tabs 3 and 4. This feature allows users to easily capture and analyze
their clustering results, facilitating further exploration or
integration into other analytical tasks within iMESc. This functionality
enhances the usability of iMESc by providing a streamlined workflow for
hierarchical clustering and the application of clustering outcomes in
subsequent analyses.</p>
<p>Users can customize several parameters in iMESc:</p>
<div id="model-setup" class="section level4 unnumbered">
<h4 class="unnumbered">1. Model setup</h4>
<table>
<colgroup>
<col width="12%" />
<col width="88%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Training Datalist:</td>
<td>Users can select the Datalist containing the data to be
clustered.</td>
</tr>
<tr class="even">
<td>Clustering target:</td>
<td>Choose between Numeric-Attribute or SOM-codebook (if any saved SOM
model).</td>
</tr>
<tr class="odd">
<td>HC Function</td>
<td>Select the clustering function.</td>
</tr>
<tr class="even">
<td>Distance*</td>
<td>Choose the distance measure to be used.</td>
</tr>
<tr class="odd">
<td>SOM-codebook</td>
<td>If clustering the SOM codebook, select the specific SOM model to be
clustered.</td>
</tr>
<tr class="even">
<td>Method</td>
<td><ul>
<li><p><strong>Ward:</strong> Minimizes within cluster variance (sum of
errors). Clusters are combined according to smallest between cluster
distance.</p></li>
<li><p><strong>Ward.D2:</strong> Same as ward.D, but the differences are
squared (sum of squared errors).</p></li>
<li><p><strong>Complete:</strong> Measures the distance between the two
most distant points in each cluster.</p></li>
<li><p><strong>Single:</strong> Measures the distance between the two
closest points in each cluster.</p></li>
<li><p><strong>Average</strong>: Measures the average (mean) distance
between each observation in each cluster, weighted by the number of
observations in each cluster.</p></li>
<li><p><strong>Mquitty</strong>: Like the average, but does not take
number of points in the cluster into account.</p></li>
<li><p><strong>Median</strong>: Measures the median distance between
each cluster’s median point.</p></li>
<li><p><strong>Centroid</strong>: Measures the distance between the
center of each cluster.</p></li>
</ul></td>
</tr>
</tbody>
</table>
<p>*Only available when clustering target is a Numeric-Attribute.
<em>When target is the SOM codebook, the distance metric is set to the
one used when training the SOM.</em></p>
</div>
<div id="panels" class="section level4 unnumbered">
<h4 class="unnumbered">2. Panels</h4>
<p>The HC results are presented in the following panels:</p>
<table>
<colgroup>
<col width="4%" />
<col width="95%" />
</colgroup>
<tbody>
<tr class="odd">
<td><ol style="list-style-type: decimal">
<li><strong>Dendrogram</strong></li>
</ol></td>
<td>A graphical representation of the hierarchical clustering structure,
displaying how clusters are merged and their distances.</td>
</tr>
<tr class="even">
<td><ol start="2" style="list-style-type: decimal">
<li><strong>Scree plot</strong></li>
</ol></td>
<td><p>This plot helps determine the optimal number of clusters. Users
can inspect the curve to find the point where adding another cluster
doesn’t significantly improve the clustering performance.</p>
<p>The split moving window analysis toolbox can aid in identifying the
“elbow” point where the curve changes drastically.</p></td>
</tr>
<tr class="odd">
<td><ol start="3" style="list-style-type: decimal">
<li><strong>Cut Dendogram</strong></li>
</ol></td>
<td><p>Generates cluster assignments of observations after cutting the
tree. The user can save the clusters assignments in the Factor-Attribute
of the current Datalist using a save flashing blue button.</p>
<p>generates the cluster assignement of the observations after cutting
the tree.<br />
A save flashing blue button allows to save the clusters assignments in
the Factor-Attribute of the current Datalist.</p></td>
</tr>
<tr class="even">
<td><ol start="4" style="list-style-type: decimal">
<li><strong>Codebook clusters*</strong></li>
</ol></td>
<td>This tab maps the training data and visualizes the SOM units that
would be clustered together. Users can also map predictions from new
data, which can be chosen from any Datalist containing the same
variables used to train the SOM. It also presents the [Variable factor
map], illustrating the influence of variables on the units’ locations
and clustering. The ‘Variable Pies’ (see Section <a
href="#variable-pies">Variable pies</a>) is available for visualizing
the relative weight of selected variables through pie charts. In
addition to the methods for selecting variables for pie visualization
described in Section <a href="#variable-pies">Variable pies</a>, users
can also use the “[Top Importance by Cluster]” option to choose which
variables to display.</td>
</tr>
<tr class="odd">
<td><ol start="5" style="list-style-type: decimal">
<li><strong>Codebook screeplot*</strong></li>
</ol></td>
<td>Generates a scree plot using either the Dendogram Height or the
Within Sum of Squares as metrics.</td>
</tr>
</tbody>
</table>
<p><em>*Only available when clustering target is the
SOM-codebook.</em></p>
</div>
<div id="top-importance-by-cluster" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>Top importance by cluster</strong></h4>
<p>In the Codebook Clusters tab with Variable Pies visualization, the
“Top Importance by Cluster” option allows users to display the relative
importance of variables based on hierarchical clustering (HC)
results.</p>
<p>The groups based on the hierarchical clustering (HC) results assigned
to neurons are used to split the codebook. For each group, the sum of
the codebook weights for each variable is calculated, providing a
measure of the absolute importance of each variable within each group.
These importance scores are normalized by the total importance of each
variable across all groups, resulting in a relative importance score for
each variable within each group. The top variables with the highest
relative importance scores for each group are identified and plotted
using pies of their weights in the codebook.</p>
</div>
</div>
<div id="k-means" class="section level3" number="8.5.3">
<h3><span class="header-section-number">8.5.3</span> <img
src="images/side8_kmeans.png" style="max-width: 54px; max-height: 30px"
width="40" /> K-means</h3>
<div class="float">
<video src="images/T12-kmeans.mp4" style="width: 600px;height: auto"
width="400" controls=""><a href="images/T12-kmeans.mp4">Video S8.5.3 -
K-Means tutorial</a></video>
<div class="figcaption">Video S8.5.3 - K-Means tutorial</div>
</div>
<p>The K-means module in iMESc performs clustering on Numeric-Attribute
or SOM-Codebook data from a selected Datalist. The objective of K-means
clustering is to divide data points into K clusters while optimizing the
within-cluster sum of squares. iMESC offers three K-means algorithms:
“<em>Hartigan-Wong</em>,” “<em>Lloyd-Forgy</em>,” and
“<em>MacQueen.</em>” Each algorithm has distinct initialization and
classification methods. Details about the algorithms can be found <a
href="https://towardsdatascience.com/three-versions-of-k-means-cf939b65f4ea">here.</a></p>
<div id="model-setup-1" class="section level4 unnumbered">
<h4 class="unnumbered">1. Model setup</h4>
<table>
<caption>Tuning K-means parameters in iMESc.</caption>
<colgroup>
<col width="15%" />
<col width="84%" />
</colgroup>
<tbody>
<tr class="odd">
<td>Clustering target:</td>
<td>Choose between Numeric-Attribute or SOM-codebook (if any saved SOM
model).</td>
</tr>
<tr class="even">
<td><strong>algorithm</strong></td>
<td>Select the preferred K-means algorithm.</td>
</tr>
<tr class="odd">
<td><strong>centers</strong></td>
<td>Specify the number of clusters to be chosen as the initial
centers.</td>
</tr>
<tr class="even">
<td><strong>iter.max</strong></td>
<td>Set the maximum number of iterations allowed for convergence.</td>
</tr>
<tr class="odd">
<td><strong>nstart</strong></td>
<td>Choose how many random sets should be used for the analysis.</td>
</tr>
<tr class="even">
<td><strong>seed</strong></td>
<td>If supplied, the seed ensures reproducibility of the results when
starting the analysis with the same seed value.</td>
</tr>
</tbody>
</table>
</div>
<div id="panels-1" class="section level4 unnumbered">
<h4 class="unnumbered">2. Panels</h4>
<ul>
<li><p>If the clustering target is the Numeric-Attribute, iMESc uses the
K-means results and the original data as arguments to create a plot.
Observations are represented by points, and if the number of variables
is greater than 2, the principal components are used for visualization;
otherwise, a boxplot is used.</p></li>
<li><p>If the clustering target is the SOM-codebook, a BMU plot is
displayed to visualize the SOM units that would be clustered
together.</p></li>
<li><p>A save flashing blue button allows the user to save the clusters
of observations in the Factor-Attribute of the training Datalist. In
this way, the assigned clusters can be further analyzed and used for
different purposes.</p></li>
</ul>
</div>
</div>
</div>
<div id="supervised-algorithms" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> <img
src="images/side9_sup.png" style="max-width: 54px; max-height: 30px"
width="40" /> Supervised Algorithms</h2>
<div class="float">
<video src="images/t10-SL.mp4" style="width: 600px;height: auto"
width="400" controls=""><a href="images/t10-SL.mp4">Video S8.5.3 -
Supervised Algorithms tutorial</a></video>
<div class="figcaption">Video S8.5.3 - Supervised Algorithms
tutorial</div>
</div>
<p>In the Supervised module of iMESc, users have access to a diverse
range of machine learning algorithms for predictive modeling. Details
about the models can be found at <a
href="https://topepo.github.io/caret/"
class="uri">https://topepo.github.io/caret/</a>. Below is an overview of
the available algorithms, including their respective model tags (used by
the <strong><code>train</code></strong> function in <code>caret</code>),
a brief description, the required packages utilized by iMESc via
<code>caret</code>, and their categories:</p>
<table style="width:99%;">
<colgroup>
<col width="8%" />
<col width="6%" />
<col width="16%" />
<col width="59%" />
<col width="8%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Category</strong></th>
<th><strong>Model Tag</strong></th>
<th><strong>Algorithm</strong></th>
<th><strong>Description</strong></th>
<th><strong>Package Required</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Tree-based</td>
<td><code>rf</code></td>
<td>Random Forest (RF)</td>
<td>An ensemble learning algorithm combining multiple decision trees to
improve predictive accuracy and reduce overfitting.</td>
<td><code>RandomForest</code></td>
</tr>
<tr class="even">
<td>Tree-based</td>
<td><code>gbm</code></td>
<td>Stochastic Gradient Boosting (GBM)</td>
<td>An ensemble learning algorithm building multiple weak learners
sequentially, correcting errors from previous ones for improved
performance.</td>
<td><code>gbm</code>, <code>plyr</code></td>
</tr>
<tr class="odd">
<td>Tree-based</td>
<td><code>cforest</code></td>
<td>Conditional Inference Random Forest</td>
<td>An implementation of random forest that provides unbiased variable
selection by conditioning on covariates.</td>
<td><code>party</code></td>
</tr>
<tr class="even">
<td>Tree-based</td>
<td><code>rpart</code></td>
<td>CART</td>
<td>Classification and Regression Trees (CART) that creates a binary
decision tree.</td>
<td><code>rpart</code></td>
</tr>
<tr class="odd">
<td>Tree-based</td>
<td><code>evtree</code></td>
<td>Tree Models from Genetic Algorithms</td>
<td>Evolutionary learning of globally optimal trees using genetic
algorithms.</td>
<td><code>evtree</code></td>
</tr>
<tr class="even">
<td>Miscellaneous Methods</td>
<td><code>nb</code></td>
<td>Naive Bayes</td>
<td>A probabilistic algorithm based on Bayes’ theorem, effective for
text classification and handling multiple classes.</td>
<td><code>klaR</code></td>
</tr>
<tr class="odd">
<td>Miscellaneous Methods</td>
<td><code>knn</code></td>
<td>k-Nearest Neighbors (KNN)</td>
<td>A simple, instance-based learning algorithm where the class of a
sample is determined by the majority class among its k nearest
neighbors.</td>
<td><code>class</code></td>
</tr>
<tr class="even">
<td>Miscellaneous Methods</td>
<td><code>xyf</code></td>
<td>Self-Organizing Maps (XYF)</td>
<td>A variant of Self-Organizing Maps (SOM) adapted for supervised
learning tasks.</td>
<td><code>Kohonen</code></td>
</tr>
<tr class="odd">
<td>Miscellaneous Methods</td>
<td><code>glm</code></td>
<td>Generalized Linear Model</td>
<td>A flexible generalization of ordinary linear regression that allows
for response variables that have error distribution models other than a
normal distribution.</td>
<td><code>stats</code></td>
</tr>
<tr class="even">
<td>Kernel</td>
<td><code>gaussprRadial</code></td>
<td>Gaussian Process with Radial Kernel</td>
<td>A non-parametric kernel-based probabilistic model.</td>
<td><code>kernlab</code></td>
</tr>
<tr class="odd">
<td>Kernel</td>
<td><code>svmLinear</code></td>
<td>SVM with Linear Kernel</td>
<td>Support Vector Machines with Linear Kernel, useful for linear
classification and regression tasks.</td>
<td><code>kernlab</code></td>
</tr>
<tr class="even">
<td>Kernel</td>
<td><code>svmRadial</code></td>
<td>SVM with Radial Basis Function Kernel</td>
<td>Support Vector Machines with Radial Basis Function Kernel, suitable
for non-linear classification and regression tasks.</td>
<td><code>kernlab</code></td>
</tr>
<tr class="odd">
<td>Kernel</td>
<td><code>svmRadialCost</code></td>
<td>SVM with Radial Basis Function Kernel</td>
<td>Support Vector Machines with Radial Basis Function Kernel with
adjustable cost parameter for non-linear classification and regression
tasks.</td>
<td><code>kernlab</code></td>
</tr>
<tr class="even">
<td>Neural Network</td>
<td><code>dnn</code></td>
<td>Deep Neural Network (Stacked AutoEncoder)</td>
<td>A deep learning model using stacked autoencoders for unsupervised
pre-training followed by supervised fine-tuning.</td>
<td><code>dnn</code></td>
</tr>
<tr class="odd">
<td>Neural Network</td>
<td><code>avNNet</code></td>
<td>Model Averaged Neural Network</td>
<td>Neural network models that are averaged to improve predictive
performance.</td>
<td><code>nnet</code></td>
</tr>
<tr class="even">
<td>Neural Network</td>
<td><code>nnet</code></td>
<td>Neural Network</td>
<td>A flexible model for classification and regression based on neural
networks.</td>
<td><code>nnet</code></td>
</tr>
<tr class="odd">
<td>Neural Network</td>
<td><code>pcaNNet</code></td>
<td>Neural Networks with Feature Extraction</td>
<td>Neural networks applied to principal components of the data for
dimensionality reduction before modeling.</td>
<td><code>nnet</code>, <code>caret</code></td>
</tr>
<tr class="even">
<td>Neural Network</td>
<td><code>monmlp</code></td>
<td>Monotone Multi-Layer Perceptron</td>
<td>A neural network that enforces monotonicity constraints on the
inputs and outputs.</td>
<td><code>monmlp</code></td>
</tr>
<tr class="odd">
<td>Neural Network</td>
<td><code>mlpML</code></td>
<td>Multi-Layer Perceptron</td>
<td>A neural network model with multiple hidden layers for complex
predictive modeling.</td>
<td><code>RSNNS</code></td>
</tr>
<tr class="even">
<td>Feature Selection</td>
<td><code>rfGA</code></td>
<td>Feature selection using Random Forest GA</td>
<td>Feature selection using RandomForest Genetic Algorithm.</td>
<td><code>caret</code></td>
</tr>
</tbody>
</table>
<div id="model-setup-2" class="section level3" number="8.6.1">
<h3><span class="header-section-number">8.6.1</span> Model setup</h3>
<ol style="list-style-type: decimal">
<li><strong>Defining X:</strong></li>
</ol>
<p>Choose the Datalist with the response variable, denoted as Y. The Y
Datalist should contain either the Variable (in case of regression, from
the Numeric-Attribute) or the Factor (in case of classification, from
the Factor-Attribute) that will serve as the response for the
algorithm’s learning and prediction processes.</p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Defining Y:</strong></li>
</ol>
<p>Users must choose the relevant Datalist for the response variable,
denoted as Y. The Y Datalist should contain either the Variable (in case
of regression, from Numeric-Attribute) or the Factor (in case of
classification, from Factor-Attribute) that will serve as the response
for the algorithm’s learning and prediction process.</p>
<ol start="3" style="list-style-type: decimal">
<li><span id="defining-partition"><strong>Defining
Partition</strong></span></li>
</ol>
<p>This step is optional, and users can proceed with training models
without using data partitioning. However, creating a partition can be
valuable for performing external validation and assessing the model’s
performance on unseen data in the future. To define a partition, the
user selects a column from the chosen Y Datalist in the “Partition”
field of the Training Tab. This column should contain information that
allows for distinguishing between training and test data.</p>
<p>The user has the flexibility to choose any column from the
Factor-Attribute of the Y Datalist for data partitioning. For example,
if the Y Datalist has a factor named “Time” with the levels (0, 1, 2),
the user can select the column “Time” in the “Partition” field and use
level 2 in the reference field. Observations corresponding to level 2
will be reserved for external validation.</p>
</div>
<div id="training" class="section level3" number="8.6.2">
<h3><span class="header-section-number">8.6.2</span> Training</h3>
<div id="tuning" class="section level4 unnumbered">
<h4 class="unnumbered">1. Tuning</h4>
<p>Choose the tuning search method using this panel.</p>
<p>In iMESc, the hyperparameter search and resampling techniques are
implemented using the <code>caret</code> R package (Kuhn, 2008).
Hyperparameters are parameters that are set before the learning process
begins and can significantly impact model performance. Each algorithm in
iMESc has specific hyperparameters, which are described in their
corresponding sections.</p>
<p>There are three types of hyperparameter tuning available in
iMESc:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Grid search:</strong> This is a linear search through
candidate values of hyperparameters. The <code>tuneLength</code>
parameter specifies the number of hyperparameter combinations to be
tested.</p></li>
<li><p><strong>Random search:</strong> The hyperparameter values are
selected randomly, and the number of combinations to be tested is
determined by the <code>tuneLength</code> parameter.</p></li>
<li><p><strong>User-defined tuning:</strong> This option allows users to
create a custom hyperparameter grid specific to the algorithm they are
using. It provides flexibility in selecting and testing desired
hyperparameter values. Users can specify the hyperparameter values as a
comma-delimited vector, and iMESc employs the R base function
<code>expand.grid</code> to generate a grid search that includes all
feasible combinations of the specified values.</p></li>
</ol>
<p>For example, in the case of a Random Forest model, the hyperparameter
<code>mtry</code> represents the number of variables randomly sampled at
each split. With <code>user-defined</code> tuning, the user can specify
which values of <code>mtry</code> they would like to test.
<code>Grid search</code> or <code>random search</code> would
automatically generate the values of <code>mtry</code> to be tested
based on the <code>tuneLength</code> parameter.</p>
</div>
<div id="model-parameters" class="section level4 unnumbered">
<h4 class="unnumbered">2. Model parameters</h4>
<p>Specify model-specific parameters that are not included in the tuning
search. Each algorith offers a specif set of parameters.</p>
</div>
<div id="resampling" class="section level4 unnumbered">
<h4 class="unnumbered">3. Resampling</h4>
<p>The resampling technique from the caret package is also implemented.
It works by dividing the training data into subsets for training and
validation, enabling the estimation of a model’s performance on part of
the data that it was not used. This procedure prevents overfitting. The
caret package offers various resampling techniques, such as k-fold
cross-validation, bootstrap resampling, and leave-one-out
cross-validation. The choice of technique depends on the specific
problem and dataset</p>
<table>
<caption>Resampling methods</caption>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<tbody>
<tr class="odd">
<td><strong>K-fold cross-validation (CV)</strong></td>
<td>It involves dividing the dataset into k equally sized subsets, and
using k-1 of these subsets for training the model while reserving the
remaining subset for testing. This process is repeated k times, with
each of the k subsets used once for testing. The performance metric is
then calculated as the average of the k test results.</td>
</tr>
<tr class="even">
<td><strong>Repeated CV</strong></td>
<td>involves repeating the k-fold CV process multiple times with
different random partitions of the data. The purpose of repeated CV is
to increase the robustness of the model evaluation, as different random
partitions may result in different performance estimates. The final
performance estimate is typically calculated as the average over all the
repeated CV iterations.</td>
</tr>
<tr class="odd">
<td><strong>bootstrap resampling</strong></td>
<td>multiple samples are created by randomly selecting data points from
the original data set with replacement. Each sample is then used for
training and validation, and the performance metric is calculated as the
average of the validation results from all samples.</td>
</tr>
<tr class="even">
<td><strong>Leave-one out</strong></td>
<td>Leave-one-out cross-validation is a special case of k-fold
cross-validation, where k is equal to the number of data points in the
data set. In this technique, each data point is used for validation
once, with the remaining data points used for training.</td>
</tr>
</tbody>
</table>
</div>
<div id="reproducibility" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>4. Reproducibility:</strong></h4>
<ul>
<li>For consistency and reproducibility, users can set a numeric value
as the seed for the random number generator. This seed value ensures
that the random processes involved in the analysis, such as
initialization of weights or sampling, remain consistent across
different runs. By using the same seed, users can obtain repeatable
results and facilitate comparison between different training
configurations.</li>
</ul>
</div>
</div>
<div id="results-1" class="section level3" number="8.6.3">
<h3><span class="header-section-number">8.6.3</span> Results</h3>
<div id="summary-1" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.1. Summary:</strong></h4>
<p>This tab presents the print outputs of the model in four panels:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Model Print:</strong> Displays the default print of the
trained model, with the resampling method used and the tuning parameters
tested, along with their respective performance metrics, such as
Accuracy and R-squared.</p></li>
<li><p><strong>Training Plot:</strong> The default plot of the trained
model.</p></li>
<li><p><strong>Model Content:</strong> Users can select and visualize
specific objects within the trained model.</p></li>
<li><p><strong>finalModel Content:</strong> Users can select and
visualize specific objects within the final model.</p></li>
</ol>
</div>
<div id="performance" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.2. Performance</strong></h4>
<p>This tab shows performance metrics for the optimal model. The tab
also includes a sheet with the performance metrics by observation.</p>
</div>
<div id="confusion-matrix" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.3. Confusion matrix:</strong></h4>
<p>For classification tasks, this section enables users to inspect the
confusion matrix and related metrics for the Optimal model or the
confusion matrix from the resampling results (using the results of all
cross-validation tests).</p>
</div>
<div id="importance" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.4. Importance</strong></h4>
<ol style="list-style-type: decimal">
<li><p>Variable importance: provides by varImp function from caret. The
users have the option to “Use model” for using the model based
tecquinique for measuring the variable importance, which is avaliable
for ‘rf’,‘gbm’,‘glm’,‘cforest’, ‘avNNet’,‘nnet’, and ‘rpart’.</p></li>
<li><p><strong>Permutation Importance:</strong> In this tab, users can
run the <a href="#permutation-feature-importance">permutation
importance</a> analysis to assess the significance of the predictors in
the model.</p></li>
</ol>
</div>
<div id="partial-dependence" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.5. Partial Dependence</strong></h4>
<p>Plot partial dependence of two variables(i.e., marginal effects)</p>
</div>
<div id="ggpairs" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.6. GGpairs</strong></h4>
<p>Displays pairwise plots for visualizing relationships between
variables.</p>
</div>
<div id="randomflorestexplainer" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.7 -
randomFlorestExplainer</strong></h4>
<p>The Random Forest Explainer in iMESc is a special tab for Random
Forest models. It utilizes several resources from the
<code>RandomForestExplainer</code> package to explore and understand the
results of the Random Forest model in more detail. The base of the
results generated by <code>RandomForestExplainer</code> is the
calculation of importance measures. The results of the
<code>RandomForestExplainer</code> are presented in five tabs:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Measures:</strong> In this tab, users can calculate the
importance metrics for the Random Forest model.</p>
<table>
<colgroup>
<col width="9%" />
<col width="90%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Measure</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>accuracy_decrease</code></td>
<td>For classification tasks, this metric calculates the mean decrease
in prediction accuracy after permuting each feature. A larger accuracy
decrease indicates that the feature is more important for
classification.</td>
</tr>
<tr class="even">
<td><code>gini_decrease</code></td>
<td>For classification tasks, this metric measures the mean decrease in
the Gini index of node impurity (increase of node purity) by splits on
each feature. A larger gini_decrease suggests that the feature is more
relevant for classification.</td>
</tr>
<tr class="odd">
<td><code>mse_increase</code></td>
<td>For regression tasks, this metric calculates the mean increase in
mean squared error after permuting each feature. A larger mse_increase
implies that the feature has more impact on the model’s
performance.</td>
</tr>
<tr class="even">
<td><code>node_purity_increase</code></td>
<td>For regression tasks, this metric measures the mean node purity
increase by splits on each feature, as indicated by the decrease in the
sum of squares. Higher node purity increase indicates greater
importance.</td>
</tr>
<tr class="odd">
<td><code>mean_minimal_depth</code></td>
<td>This metric represents the mean minimal depth of variables
calculated in one of three ways specified by the parameter mean_sample.
It indicates the relative importance of variables, with smaller values
suggesting higher importance.</td>
</tr>
<tr class="even">
<td><code>no_of_trees</code></td>
<td>The total number of trees in which a split on each feature occurs. A
higher number of trees featuring a split on a particular feature
indicates its importance in the model.</td>
</tr>
<tr class="odd">
<td><code>no_of_nodes</code></td>
<td>The total number of nodes that use each feature for splitting. In
shallow trees, the number of nodes using a feature is typically equal to
the number of trees where the feature is split, providing insights into
the feature’s significance.</td>
</tr>
<tr class="even">
<td><code>times_a_root</code></td>
<td>The total number of trees in which each feature is used for
splitting the root node. When a feature is used frequently to split the
root node, it indicates its significance in determining the model’s
primary decision boundaries.</td>
</tr>
<tr class="odd">
<td><code>p_value</code></td>
<td>The p-value for the one-sided binomial test using a specific
distribution. This p-value can provide information about the
significance of each feature in the model. A smaller p-value suggests
higher importance for the feature.</td>
</tr>
</tbody>
</table></li>
<li><p><strong>Min Depth Distr:</strong> This tab plots the top
variables according to mean minimal depth calculated using top trees.
The mean minimal depth can be calculated in three different ways using
the <code>mean_sample</code> argument. The calculation differs in how
they treat missing values that appear when a feature is not used for
tree splitting. As a result, the ranking of variables may change for
each calculation. The mean minimal depth is indicated by a vertical bar
with the mean value beside it. The smaller the mean minimal depth, the
more important the variable is, and the higher up the y-axis the
variable will be. The rainbow gradient reveals the min and max minimal
depth for each variable. The bigger the proportion of minimal depth
zero, the more frequent the variable is the root of a tree. The smaller
the proportion of NA minimal depth (gray blocks), the more frequent the
variable is used for splitting trees. The range of the x-axis is from
zero to the maximum number of trees for the feature.</p></li>
<li><p><strong>Multi-way:</strong> This tab allows users to explore
values of x_measure and y_measure, which specify measures to use on the
x and y-axis.</p></li>
<li><p><strong>Relationships:</strong> This tab plots the selected
importance measures pairwise against each other (Between importance tab)
and by plotting importance measures against rankings instead of raw
measures (Between rankings tab).</p></li>
<li><p><strong>Interactions:</strong> This tab generates a plot with
bars arranged from the most frequent interactions occurring on the left
side of the plot to the least frequent occurring interactions on the
right side of the plot. The horizontal red line represents the minimum
mean_min_depth, and the black lollipop represents the
uncond_mean_min_depth.</p></li>
</ol>
</div>
<div id="model--specific-plots" class="section level4 unnumbered">
<h4 class="unnumbered"><strong>2.7. - Model -specific
plots</strong></h4>
<ul>
<li><p>Trees (rf, cforest): Select and plot one tree from the
forest.</p></li>
<li><p>Tree Plot (rpart and evtree): Plot the tree result.</p></li>
<li><p>BMU Plot (xyf): Best matching unit plot.</p></li>
<li><p>Network Plot (avNNet, nnet, pcaNNet, monmlp, mlpML): Visualize
the network and its weights.</p></li>
<li><p>GAM Style (monmlp): Generalized Additive Model style
plots.</p></li>
<li><p>Densities (nb): Display density plots.</p></li>
</ul>
</div>
<div id="permutation-feature-importance"
class="section level4 unnumbered">
<h4 class="unnumbered">Permutation Feature Importance</h4>
<p>Permutation Feature Importance is a powerful technique used to assess
the importance of each feature in a machine learning model. It helps
users understand which features have the most influence on the model’s
predictions and provides insights into the significance of each feature
in the overall model performance. The steps followed by iMESc to perform
feature importance permutation are as follows:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Hypothesis</strong>: Test whether the observed predictive
power of a feature differ significantly from a random null
distribution..</p></li>
<li><p><strong>Observed Metric</strong>: Use accuracy (for
classification) or R-squared (for regression) as the performance
metric.</p></li>
<li><p><strong>Permutation Process</strong>: Randomly shuffle the
feature’s values while keeping the other variables unchanged.</p></li>
<li><p><strong>Null Distribution</strong>: Repeat the permutation
process to create a null distribution of permuted metrics.</p></li>
<li><p><strong>Comparison</strong>: Compare the observed metric to the
null distribution to assess the feature’s importance.</p></li>
<li><p><strong>P-value</strong>: Calculate the p-value, indicating the
statistical significance of the feature’s importance.</p></li>
<li><p><strong>User Decision</strong>: Decide whether the feature is
statistically significant based on the p-value and significance
level.</p></li>
</ol>
<p>The final output is a feature shuffling impact plot, showing
performance decay on the x-axis and features on the y-axis. Significant
and non-significant variables are differentiated by colors, providing a
clear visualization of the significant features.</p>
</div>
</div>
<div id="predict-1" class="section level3" number="8.6.4">
<h3><span class="header-section-number">8.6.4</span> Predict</h3>
<p>The Predict tab header offers two options for making predictions:</p>
<ol style="list-style-type: decimal">
<li><p>Predict using the Partition: If the user defined a data partition
during the training phase (see <a href="#defining-partition">Defining
Partition</a>), they can use this option to make predictions on the
“Test” data, which was set aside for external validation.</p></li>
<li><p>Predict using a Datalist: With this option, users can make
predictions on a new dataset (Datalist) that was not used during model
training. The user needs to choose the appropriate Datalist containing
the same columns names used for training.</p></li>
</ol>
<p>The output is displayed in two sections in the Predict tab:</p>
<ul>
<li><p><strong>Results:</strong> This section shows the predictions per
observation in a sheet format. Users can either download the sheet or
create a new Datalist with these results for further analysis within
iMESc.</p></li>
<li><p><strong>Performance:</strong> In this tab, users can explore
various performance metrics to evaluate the trained model. The available
performance metrics may include R-squared, Accuracy, and Confusion
tables, among others, depending on the specific algorithm and problem
type. The type of prediction (Partition or Datalist) selected by the
user determines the data used for performance evaluation:</p>
<ul>
<li><p>If the user selects “Partition” as the prediction option, iMESc
uses the observations kept out during the training phase (i.e., the
“Test” data from the data partition) for performance evaluation. The
model’s predictions on the “Test” data are compared with the true values
to calculate the performance metrics.</p></li>
<li><p>If the user selects “Datalist” as the prediction option, they
need to choose the corresponding Datalist containing the new data that
was not used during training. Additionally, the user must specify the
appropriate Variable or Factor from the Datalist to be used for external
validation. In this case, the model’s predictions on the new data are
compared with the actual values provided in the Datalist to assess the
model’s performance.</p></li>
</ul></li>
</ul>
</div>
</div>
<div id="compare-models" class="section level2" number="8.7">
<h2><span class="header-section-number">8.7</span> <img
src="images/side15_comp.png" style="max-width: 54px; max-height: 30px"
width="40" /> Compare Models</h2>
<p>This tab is designed for model comparison. In this tab, the user
selects the Datalist containing the models (with similar resampling
schemes) to be compared and explores the results through 8 tabs:</p>
<ul>
<li><p>1.1. Summary: table with performance metrics.</p></li>
<li><p>1.2. bwplot: boxplot of performance metrics.</p></li>
<li><p>1.3. densityplot: creates density plots that show the
distribution of each feature in the dataset, grouped by the levels of
the target variable.</p></li>
<li><p>1.4. dotplot: creates a dot plot of the model performance
metrics.</p></li>
<li><p>1.5. parallelplot: creates a plot where each axis represents a
different performance metric, and the lines connecting the points for
each model indicate its performance on each metric.</p></li>
<li><p>1.6. splom: creates scatterplot matrices, where each scatterplot
in the matrix represents the relationship between two performance
metrics, and the points for each model are plotted in the corresponding
location in each scatterplot.</p></li>
<li><p>1.7. P-values (pairwise comparisons): computes pairwise
comparisons between models using the t-test and returns a matrix
containing the p-values for each comparison.</p></li>
</ul>
</div>
</div>
<div id="packages-functions" class="section level1" number="9">
<h1><span class="header-section-number">9</span> Packages &amp;
functions</h1>
<p>In this section, we present the key packages and functions used in
the development of iMESc. While iMESc utilizes a wide range of packages
and functions, this section highlights some of the key packages and
their corresponding functions that play a crucial role throughout the
entire app and in various analytical tasks. Please note that these
tables might not be exhaustive, but they cover the most relevant
packages and functions used in the iMESc software. The version numbers
provided are subject to change with future package updates.</p>
<div id="table-1-packages-and-functions-for-analytical-tasks"
class="section level2" number="9.1">
<h2><span class="header-section-number">9.1</span> <strong>Table 1:
Packages and Functions for Analytical Tasks</strong></h2>
<p>In this table, we highlight the packages and functions used for
various analytical tasks within iMESc.</p>
<table style="width:99%;">
<colgroup>
<col width="9%" />
<col width="3%" />
<col width="69%" />
<col width="16%" />
</colgroup>
<thead>
<tr class="header">
<th>Package</th>
<th>Version</th>
<th>Functions</th>
<th>Task</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>automap</code></td>
<td>1.1.9</td>
<td><code>autofitVariogram</code></td>
<td>Spatial Tools</td>
</tr>
<tr class="even">
<td><code>aweSOM</code></td>
<td>1.3</td>
<td><code>somDist</code>, <code>somQuality</code></td>
<td>Self-Organizing Maps</td>
</tr>
<tr class="odd">
<td><code>caret</code></td>
<td>6.0.94</td>
<td><code>createDataPartition</code>, <code>findCorrelation</code>,
<code>confusionMatrix</code>, <code>gafsControl</code>,
<code>getModelInfo</code>, <code>postResample</code>,
<code>varImp</code>, <code>MAE</code>, <code>multiClassSummary</code>,
<code>RMSE</code>, <code>train</code>, <code>trainControl</code></td>
<td>Supervised Algorithms, Pre-processing tools</td>
</tr>
<tr class="even">
<td><code>dendextend</code></td>
<td>1.17.1</td>
<td><code>as.ggdend</code>, <code>color_branches</code>,
<code>get_leaves_branches_col</code>,
<code>heights_per_k.dendrogram</code>,
<code>highlight_branches_lwd</code>, <code>labels_colors</code>,
<code>prepare.ggdend</code>, <code>theme_dendro</code></td>
<td>Hierarchical Clustering</td>
</tr>
<tr class="odd">
<td><code>GGally</code></td>
<td>2.2.1</td>
<td><code>ggally_cor</code>, <code>ggally_densityDiag</code>,
<code>ggally_points</code>, <code>ggpairs</code>,
<code>ggally_barDiag</code></td>
<td>Descriptive Tools</td>
</tr>
<tr class="even">
<td><code>ggforce</code></td>
<td>0.4.1</td>
<td><code>geom_arc_bar</code></td>
<td>Self-Organizing Maps</td>
</tr>
<tr class="odd">
<td><code>ggparty</code></td>
<td>1.0.0</td>
<td><code>geom_edge</code>, <code>geom_edge_label</code>,
<code>geom_node_info</code>, <code>geom_node_plot</code>,
<code>geom_node_splitvar</code>, <code>ggparty</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="even">
<td><code>ggraph</code></td>
<td>2.1.0</td>
<td><code>geom_edge_diagonal</code>, <code>geom_edge_link</code>,
<code>geom_node_label</code>, <code>geom_node_point</code>,
<code>geom_node_text</code>, <code>ggraph</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="odd">
<td><code>ggridges</code></td>
<td>0.5.6</td>
<td><code>geom_density_ridges</code></td>
<td>Descriptive Tools</td>
</tr>
<tr class="even">
<td><code>gstat</code></td>
<td>2.1.1</td>
<td><code>gstat</code>, <code>gstat.cv</code>,
<code>variogramLine</code>, <code>vgm</code>, <code>idw</code></td>
<td>Spatial Tools</td>
</tr>
<tr class="odd">
<td><code>kernlab</code></td>
<td>0.9.32</td>
<td><code>ksvm</code>, <code>sigest</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="even">
<td><code>klaR</code></td>
<td>1.7.3</td>
<td><code>dkernel</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="odd">
<td><code>kohonen</code></td>
<td>3.0.12</td>
<td><code>getCodes</code>, <code>object.distances</code>,
<code>somgrid</code>, <code>supersom</code>,
<code>unit.distances</code>, <code>map</code>,
<code>check.whatmap</code>, <code>nunits</code>,
<code>classvec2classmat</code>, <code>classmat2classvec</code>,
<code>add.cluster.boundaries</code>, <code>dist2WU</code></td>
<td>Self-Organizing Maps</td>
</tr>
<tr class="even">
<td><code>lattice</code></td>
<td>0.21.9</td>
<td><code>bwplot</code>, <code>densityplot</code>, <code>dotplot</code>,
<code>parallelplot</code>, <code>splom</code>,
<code>trellis.par.set</code>, <code>xyplot</code></td>
<td>Compare Models</td>
</tr>
<tr class="odd">
<td><code>leaflet</code></td>
<td>2.2.1</td>
<td><code>leafletOutput</code>, <code>renderLeaflet</code></td>
<td>Spatial Tools</td>
</tr>
<tr class="even">
<td><code>Metrics</code></td>
<td>0.1.4</td>
<td><code>mae</code>, <code>mape</code>, <code>mse</code>,
<code>rmse</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="odd">
<td><code>mice</code></td>
<td>3.16.0</td>
<td><code>complete</code>, <code>mice</code></td>
<td>Pre-processing tools</td>
</tr>
<tr class="even">
<td><code>NeuralNetTools</code></td>
<td>1.5.3</td>
<td><code>olden</code>, <code>neuralweights</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="odd">
<td><code>party</code></td>
<td>1.3.14</td>
<td><code>prettytree</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="even">
<td><code>partykit</code></td>
<td>1.2.20</td>
<td><code>as.party</code>, <code>as.partynode</code>,
<code>gettree</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="odd">
<td><code>pdp</code></td>
<td>0.8.1</td>
<td><code>partial</code>, <code>exemplar</code>,
<code>plotPartial</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="even">
<td><code>plot3D</code></td>
<td>1.4.1</td>
<td><code>persp3D</code>, <code>perspbox</code></td>
<td>Spatial Tools</td>
</tr>
<tr class="odd">
<td><code>plotly</code></td>
<td>4.10.4</td>
<td><code>add_surface</code>, <code>add_trace</code>,
<code>plot_ly</code>, <code>plotlyOutput</code>,
<code>renderPlotly</code>, <code>style</code></td>
<td>Spatial Tools, Supervised Algorithms</td>
</tr>
<tr class="even">
<td><code>randomForest</code></td>
<td>4.7.1.1</td>
<td><code>importance</code>, <code>getTree</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="odd">
<td><code>randomForestExplainer</code></td>
<td>0.10.1</td>
<td><code>important_variables</code>,
<code>min_depth_interactions</code>,
<code>plot_importance_rankings</code>,
<code>plot_min_depth_interactions</code>,
<code>measure_importance</code>, <code>min_depth_distribution</code>,
<code>plot_multi_way_importance</code></td>
<td>Supervised Algorithms</td>
</tr>
<tr class="even">
<td><code>raster</code></td>
<td>3.6.26</td>
<td><code>crop</code>, <code>extent</code>, <code>mask</code>,
<code>raster</code>, <code>rasterize</code>,
<code>rasterToPoints</code>, <code>values</code>,
<code>writeRaster</code>, <code>crs</code>, <code>rasterFromXYZ</code>,
<code>ratify</code></td>
<td>Spatial Tools</td>
</tr>
<tr class="odd">
<td><code>segRDA</code></td>
<td>1.0.2</td>
<td><code>bp</code>, <code>extract</code>, <code>OrdData</code></td>
<td>Descriptive tools</td>
</tr>
<tr class="even">
<td><code>sf</code></td>
<td>1.0.15</td>
<td><code>st_as_sf</code>, <code>st_bbox</code>, <code>st_crs</code>,
<code>st_set_crs</code>, <code>st_transform</code>,
<code>st_cast</code>, <code>st_coordinates</code>,
<code>st_geometry_type</code>, <code>st_point</code>,
<code>st_sfc</code></td>
<td>Spatial Tools</td>
</tr>
<tr class="odd">
<td><code>shinyTree</code></td>
<td>0.3.1</td>
<td><code>get_selected</code>, <code>renderTree</code>,
<code>shinyTree</code></td>
<td>Pre-processing tools</td>
</tr>
<tr class="even">
<td><code>sp</code></td>
<td>2.1.3</td>
<td><code>coordinates</code>, <code>zerodist</code>, <code>CRS</code>,
<code>spsample</code></td>
<td>Spatial Tools</td>
</tr>
<tr class="odd">
<td><code>vegan</code></td>
<td>2.6.4</td>
<td><code>decostand</code>, <code>diversity</code>,
<code>estimateR</code>, <code>fisher.alpha</code>,
<code>specnumber</code></td>
<td>Diversity tools</td>
</tr>
<tr class="even">
<td><code>webshot</code></td>
<td>0.5.5</td>
<td><code>webshot</code></td>
<td>Spatial Tools</td>
</tr>
</tbody>
</table>
</div>
<div id="table-2-packages-and-functions-used-throughout-the-app"
class="section level2" number="9.2">
<h2><span class="header-section-number">9.2</span> <strong>Table 2:
Packages and Functions Used Throughout the App</strong></h2>
<p>This table presents the packages and their respective functions that
are utilized across the entire app. These packages are essential for
data manipulation, visualization, interactive features, and more.</p>
<table style="width:100%;">
<colgroup>
<col width="2%" />
<col width="1%" />
<col width="96%" />
</colgroup>
<thead>
<tr class="header">
<th>Package</th>
<th>Version</th>
<th>Functions</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>base64enc</code></td>
<td>0.1.3</td>
<td><code>dataURI</code></td>
</tr>
<tr class="even">
<td><code>colorspace</code></td>
<td>2.1.0</td>
<td><code>hex2RGB</code>, <code>mixcolor</code></td>
</tr>
<tr class="odd">
<td><code>colourpicker</code></td>
<td>1.3.0</td>
<td><code>colourInput</code></td>
</tr>
<tr class="even">
<td><code>data.table</code></td>
<td>1.15.0</td>
<td><code>melt</code>, <code>rbindlist</code></td>
</tr>
<tr class="odd">
<td><code>devtools</code></td>
<td>2.4.5</td>
<td><code>source_url</code></td>
</tr>
<tr class="even">
<td><code>DT</code></td>
<td>0.32</td>
<td><code>DTOutput</code>, <code>renderDT</code>,
<code>datatable</code>, <code>dataTableOutput</code>,
<code>formatStyle</code>, <code>renderDataTable</code>,
<code>JS</code></td>
</tr>
<tr class="odd">
<td><code>e1071</code></td>
<td>1.7.14</td>
<td><code>allShortestPaths</code></td>
</tr>
<tr class="even">
<td><code>foreach</code></td>
<td>1.5.2</td>
<td><code>foreach</code></td>
</tr>
<tr class="odd">
<td><code>gbRd</code></td>
<td>0.4.11</td>
<td><code>Rd_fun</code></td>
</tr>
<tr class="even">
<td><code>ggnewscale</code></td>
<td>0.4.10</td>
<td><code>new_scale_fill</code>, <code>new_scale_color</code>,
<code>new_scale</code></td>
</tr>
<tr class="odd">
<td><code>ggplot2</code></td>
<td>3.5.1</td>
<td><code>discrete_scale</code>, <code>element_rect</code>,
<code>geom_sf</code>, <code>ggplot</code>, <code>layer</code>,
<code>scale_color_gradientn</code>, <code>theme</code>,
<code>aes</code>, <code>coord_cartesian</code>, <code>coord_flip</code>,
<code>element_blank</code>, <code>element_line</code>,
<code>element_text</code>, <code>geom_label</code>,
<code>geom_segment</code>, <code>geom_text</code>, <code>ggtitle</code>,
<code>margin</code>, <code>scale_colour_identity</code>,
<code>scale_linetype_identity</code>, <code>scale_size_identity</code>,
<code>scale_x_discrete</code>, <code>scale_y_reverse</code>,
<code>theme_bw</code>, <code>theme_classic</code>,
<code>theme_dark</code>, <code>theme_grey</code>,
<code>theme_light</code>, <code>theme_linedraw</code>,
<code>theme_minimal</code>, <code>theme_void</code>, <code>xlab</code>,
<code>ylab</code>, <code>coord_fixed</code>, <code>geom_line</code>,
<code>geom_point</code>, <code>geom_polygon</code>,
<code>geom_vline</code>, <code>guide_legend</code>, <code>guides</code>,
<code>scale_color_manual</code>, <code>scale_fill_gradientn</code>,
<code>scale_fill_manual</code>, <code>scale_linetype_manual</code>,
<code>scale_x_continuous</code>, <code>scale_y_continuous</code>,
<code>sec_axis</code>, <code>standardise_aes_names</code>,
<code>geom_raster</code>, <code>labs</code>,
<code>scale_colour_manual</code>, <code>facet_wrap</code>,
<code>geom_freqpoly</code>, <code>vars</code></td>
</tr>
<tr class="even">
<td><code>ggrepel</code></td>
<td>0.9.5</td>
<td><code>geom_label_repel</code></td>
</tr>
<tr class="odd">
<td><code>htmlwidgets</code></td>
<td>1.6.4</td>
<td><code>saveWidget</code></td>
</tr>
<tr class="even">
<td><code>igraph</code></td>
<td>2.0.2</td>
<td><code>delete_vertices</code>, <code>graph_from_data_frame</code>,
<code>V</code></td>
</tr>
<tr class="odd">
<td><code>MLmetrics</code></td>
<td>1.1.1</td>
<td><code>R2_Score</code>, <code>F1_Score</code>,
<code>FBeta_Score</code>, <code>Gini</code>, <code>MAE</code>,
<code>MAPE</code>, <code>MedianAE</code>, <code>MedianAPE</code>,
<code>MSE</code>, <code>NormalizedGini</code>,
<code>Poisson_LogLoss</code>, <code>RAE</code>, <code>RMSE</code>,
<code>RMSLE</code>, <code>RMSPE</code>, <code>RRSE</code></td>
</tr>
<tr class="even">
<td><code>pROC</code></td>
<td>1.18.5</td>
<td><code>multiclass.roc</code></td>
</tr>
<tr class="odd">
<td><code>purrr</code></td>
<td>1.0.2</td>
<td><code>walk2</code></td>
</tr>
<tr class="even">
<td><code>RColorBrewer</code></td>
<td>1.1.3</td>
<td><code>brewer.pal</code></td>
</tr>
<tr class="odd">
<td><code>readr</code></td>
<td>2.1.4</td>
<td><code>read_file</code></td>
</tr>
<tr class="even">
<td><code>readxl</code></td>
<td>1.4.3</td>
<td><code>cell_cols</code>, <code>excel_sheets</code>,
<code>read_excel</code></td>
</tr>
<tr class="odd">
<td><code>reshape</code></td>
<td>0.8.9</td>
<td><code>melt</code></td>
</tr>
<tr class="even">
<td><code>reshape2</code></td>
<td>1.4.4</td>
<td><code>melt</code></td>
</tr>
<tr class="odd">
<td><code>scales</code></td>
<td>1.3.0</td>
<td><code>cbreaks</code>, <code>extended_breaks</code>,
<code>rescale</code>, <code>col_numeric</code>,
<code>label_number</code></td>
</tr>
<tr class="even">
<td><code>shiny</code></td>
<td>1.8.0</td>
<td><code>actionButton</code>, <code>actionLink</code>,
<code>callModule</code>, <code>checkboxInput</code>,
<code>column</code>, <code>div</code>, <code>downloadButton</code>,
<code>downloadHandler</code>, <code>downloadLink</code>,
<code>em</code>, <code>eventReactive</code>, <code>fluidRow</code>,
<code>HTML</code>, <code>icon</code>, <code>insertTab</code>,
<code>isolate</code>, <code>modalButton</code>,
<code>modalDialog</code>, <code>moduleServer</code>,
<code>navbarPage</code>, <code>need</code>, <code>NS</code>,
<code>numericInput</code>, <code>observe</code>,
<code>observeEvent</code>, <code>plotOutput</code>,
<code>reactive</code>, <code>reactiveVal</code>,
<code>reactiveValues</code>, <code>removeModal</code>,
<code>removeTab</code>, <code>renderPlot</code>,
<code>renderPrint</code>, <code>renderUI</code>, <code>req</code>,
<code>selectInput</code>, <code>showModal</code>, <code>span</code>,
<code>strong</code>, <code>tabPanel</code>, <code>tabsetPanel</code>,
<code>textInput</code>, <code>uiOutput</code>,
<code>updateCheckboxInput</code>, <code>updateNumericInput</code>,
<code>updateTabsetPanel</code>, <code>updateTextInput</code>,
<code>validate</code>, <code>withProgress</code>, <code>img</code>,
<code>getDefaultReactiveDomain</code>, <code>incProgress</code>,
<code>a</code>, <code>absolutePanel</code>, <code>br</code>,
<code>code</code>, <code>conditionalPanel</code>, <code>h3</code>,
<code>h4</code>, <code>h5</code>, <code>htmlOutput</code>,
<code>p</code>, <code>renderTable</code>, <code>splitLayout</code>,
<code>verbatimTextOutput</code></td>
</tr>
<tr class="odd">
<td><code>shinyBS</code></td>
<td>0.61.1</td>
<td><code>bsTooltip</code>, <code>addPopover</code>,
<code>bsButton</code>, <code>popify</code>, <code>tipify</code></td>
</tr>
<tr class="even">
<td><code>shinybusy</code></td>
<td>0.3.2</td>
<td><code>add_busy_spinner</code></td>
</tr>
<tr class="odd">
<td><code>shinydashboardPlus</code></td>
<td>2.0.3</td>
<td><code>dashboardFooter</code>, <code>dashboardHeader</code>,
<code>dashboardPage</code>, <code>dashboardSidebar</code></td>
</tr>
<tr class="even">
<td><code>shinyjs</code></td>
<td>2.1.0</td>
<td><code>delay</code>, <code>hide</code>, <code>onevent</code>,
<code>runjs</code>, <code>hidden</code>, <code>useShinyjs</code>,
<code>addClass</code>, <code>colourInput</code>, <code>reset</code>,
<code>toggle</code>, <code>toggleClass</code>, <code>addCssClass</code>,
<code>removeCssClass</code>, <code>toggleState</code></td>
</tr>
<tr class="odd">
<td><code>shinyWidgets</code></td>
<td>0.8.1</td>
<td><code>pickerInput</code>, <code>radioGroupButtons</code>,
<code>updatePickerInput</code>, <code>updateVirtualSelect</code>,
<code>virtualSelectInput</code>, <code>switchInput</code>,
<code>updateSwitchInput</code>, <code>dropMenu</code>,
<code>pickerOptions</code>, <code>updateRadioGroupButtons</code></td>
</tr>
<tr class="even">
<td><code>sortable</code></td>
<td>0.5.0</td>
<td><code>rank_list</code></td>
</tr>
<tr class="odd">
<td><code>stringr</code></td>
<td>1.5.1</td>
<td><code>str_length</code>, <code>str_replace_all</code></td>
</tr>
<tr class="even">
<td><code>tibble</code></td>
<td>3.2.1</td>
<td><code>rownames_to_column</code></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="model-specific-tunning-supervised-alorithms"
class="section level1" number="10">
<h1><span class="header-section-number">10</span> Model-specific tunning
(Supervised alorithms)</h1>
<div id="random-forest" class="section level2" number="10.1">
<h2><span class="header-section-number">10.1</span> Random Forest</h2>
<table>
<colgroup>
<col width="6%" />
<col width="93%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ntree</td>
<td>Number of trees to grow. This should not be set to too small a
number, to ensure that every input row gets predicted at least a few
times.</td>
</tr>
<tr class="even">
<td>replace</td>
<td>Should sampling of cases be done with or without replacement?</td>
</tr>
<tr class="odd">
<td>nodesize</td>
<td>Minimum size of terminal nodes. Setting this number larger causes
smaller trees to be grown (and thus take less time). Note that the
default values are different for classification (1) and regression
(5).</td>
</tr>
<tr class="even">
<td>maxnodes</td>
<td>Maximum number of terminal nodes trees in the forest can have. If
not given, trees are grown to the maximum possible (subject to limits by
nodesize). If set larger than maximum possible, a warning is
issued.</td>
</tr>
<tr class="odd">
<td>nPerm</td>
<td>Number of times the OOB data are permuted per tree for assessing
variable importance. Number larger than 1 gives slightly more stable
estimate, but not very effective. Currently only implemented for
regression.</td>
</tr>
<tr class="even">
<td>norm.votes</td>
<td>If TRUE (default), the final result of votes are expressed as
fractions. If FALSE, raw vote counts are returned (useful for combining
results from different runs). Ignored for regression.</td>
</tr>
</tbody>
</table>
</div>
<div id="naive-bayes" class="section level2" number="10.2">
<h2><span class="header-section-number">10.2</span> Naive Bayes</h2>
<table>
<colgroup>
<col width="6%" />
<col width="93%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>bw</td>
<td>The smoothing bandwidth to be used. The kernels are scaled such that
this is the standard deviation of the smoothing kernel. Can also be a
character string giving a rule to choose the bandwidth. The default is
“nrd0”.</td>
</tr>
<tr class="even">
<td>window</td>
<td>A character string giving the smoothing kernel to be used. Must
partially match one of “gaussian”, “rectangular”, “triangular”,
“epanechnikov”, “biweight”, “cosine” or “optcosine”. Default is
“gaussian”.</td>
</tr>
<tr class="odd">
<td>kernel</td>
<td>A character string giving the smoothing kernel to be used. Must
partially match one of “gaussian”, “rectangular”, “triangular”,
“epanechnikov”, “biweight”, “cosine” or “optcosine”. Default is
“gaussian”.</td>
</tr>
</tbody>
</table>
</div>
<div id="k-nearest-neighbors" class="section level2" number="10.3">
<h2><span class="header-section-number">10.3</span> k-Nearest
Neighbors</h2>
<table>
<colgroup>
<col width="7%" />
<col width="92%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>l</td>
<td>Minimum vote for a definite decision, otherwise doubt. Less than k-l
dissenting votes are allowed, even if k is increased by ties.</td>
</tr>
<tr class="even">
<td>use.all</td>
<td>Controls handling of ties. If true, all distances equal to the kth
largest are included. If false, a random selection of distances equal to
the kth is chosen to use exactly k neighbors.</td>
</tr>
</tbody>
</table>
</div>
<div id="stochastic-gradient-boosting" class="section level2"
number="10.4">
<h2><span class="header-section-number">10.4</span> Stochastic Gradient
Boosting</h2>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>bag.fraction</td>
<td>The fraction of the training set observations randomly selected to
propose the next tree in the expansion. Default is 0.5.</td>
</tr>
</tbody>
</table>
</div>
<div id="self-organizing-maps-1" class="section level2" number="10.5">
<h2><span class="header-section-number">10.5</span> Self-Organizing
Maps</h2>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>rlen</td>
<td>The number of times the complete data set will be presented to the
network.</td>
</tr>
<tr class="even">
<td>alpha</td>
<td>Learning rate, a vector of two numbers indicating the amount of
change. Default is to decline linearly from 0.05 to 0.01 over rlen
updates. Not used for the batch algorithm.</td>
</tr>
<tr class="odd">
<td>maxNA.fraction</td>
<td>The maximal fraction of values that may be NA to prevent the row
from being removed.</td>
</tr>
<tr class="even">
<td>dist.fcts</td>
<td>Vector of distance functions to be used for the individual data
layers. Default is “sumofsquares” for continuous data, and “tanimoto”
for factors.</td>
</tr>
<tr class="odd">
<td>mode</td>
<td>Type of learning algorithm.</td>
</tr>
<tr class="even">
<td>normalizeDataLayers</td>
<td>Boolean, indicating whether distance.weights should be calculated.
If normalizeDataLayers == FALSE, user weights are applied to the data
immediately.</td>
</tr>
</tbody>
</table>
</div>
<div id="generalized-linear-model" class="section level2" number="10.6">
<h2><span class="header-section-number">10.6</span> Generalized Linear
Model</h2>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>method</td>
<td>The method to be used in fitting the model. The default method
“glm.fit” uses iteratively reweighted least squares (IWLS).</td>
</tr>
<tr class="even">
<td>singular.ok</td>
<td>Logical; if FALSE, a singular fit is an error.</td>
</tr>
<tr class="odd">
<td>epsilon</td>
<td>Positive convergence tolerance; the iterations converge when</td>
</tr>
<tr class="even">
<td>maxit</td>
<td>Integer giving the maximal number of IWLS iterations.</td>
</tr>
</tbody>
</table>
</div>
<div id="stacked-autoencoder-deep-neural-network" class="section level2"
number="10.7">
<h2><span class="header-section-number">10.7</span> Stacked AutoEncoder
Deep Neural Network</h2>
<table>
<colgroup>
<col width="17%" />
<col width="82%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>activationfun</td>
<td>Activation function of hidden unit. Can be “sigm”, “linear” or
“tanh”. Default is “sigm”.</td>
</tr>
<tr class="even">
<td>learningrate</td>
<td>Learning rate for gradient descent. Default is 0.8.</td>
</tr>
<tr class="odd">
<td>momentum</td>
<td>Momentum for gradient descent. Default is 0.5.</td>
</tr>
<tr class="even">
<td>learningrate_scale</td>
<td>Learning rate will be multiplied by this scale after every
iteration. Default is 1.</td>
</tr>
<tr class="odd">
<td>output</td>
<td>Function of output unit. Can be “sigm”, “linear” or “softmax”.
Default is “sigm”.</td>
</tr>
<tr class="even">
<td>sae_output</td>
<td>Function of autoencoder output unit. Can be “sigm”, “linear” or
“softmax”. Default is “linear”.</td>
</tr>
<tr class="odd">
<td>numepochs</td>
<td>Number of iterations for samples. Default is 3.</td>
</tr>
<tr class="even">
<td>batchsize</td>
<td>Size of mini-batch. Default is 100.</td>
</tr>
</tbody>
</table>
</div>
<div id="conditional-inference-random-forest" class="section level2"
number="10.8">
<h2><span class="header-section-number">10.8</span> Conditional
Inference Random Forest</h2>
<table>
<colgroup>
<col width="11%" />
<col width="88%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>teststat</td>
<td>A character specifying the type of the test statistic to be
applied.</td>
</tr>
<tr class="even">
<td>testtype</td>
<td>A character specifying how to compute the distribution of the test
statistic.</td>
</tr>
<tr class="odd">
<td>mincriterion</td>
<td>The value of the test statistic or 1 - p-value that must be exceeded
to implement a split.</td>
</tr>
<tr class="even">
<td>savesplitstats</td>
<td>A logical determining whether standardized two-sample statistics for
split point estimate are saved for each primary split.</td>
</tr>
<tr class="odd">
<td>ntree</td>
<td>Number of trees to grow in a forest.</td>
</tr>
<tr class="even">
<td>replace</td>
<td>A logical indicating whether sampling of observations is done with
or without replacement.</td>
</tr>
<tr class="odd">
<td>fraction</td>
<td>Fraction of number of observations to draw without replacement (only
relevant if replace = FALSE).</td>
</tr>
</tbody>
</table>
</div>
<div id="gaussian-process-with-radial-basis-function-kernel"
class="section level2" number="10.9">
<h2><span class="header-section-number">10.9</span> Gaussian Process
with Radial Basis Function Kernel</h2>
<table>
<colgroup>
<col width="12%" />
<col width="87%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Parameter</strong></th>
<th><strong>Description</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>scaled</td>
<td>A logical vector indicating the variables to be scaled. Default
scales data to zero mean and unit variance.</td>
</tr>
<tr class="even">
<td>var</td>
<td>The initial noise variance for regression. Default is 0.001.</td>
</tr>
<tr class="odd">
<td>tol</td>
<td>Tolerance of termination criterion. Default is 0.001.</td>
</tr>
</tbody>
</table>
</div>
<div id="svmlinear---support-vector-machines-with-linear-kernel"
class="section level2" number="10.10">
<h2><span class="header-section-number">10.10</span> svmLinear - Support
Vector Machines with Linear Kernel</h2>
<table>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>nu</strong></td>
<td>Parameter needed for <code>nu-svc</code>, <code>one-svc</code>, and
<code>nu-svr</code>. Sets the upper bound on training error and lower
bound on fraction of data points to become Support Vectors (default:
0.2).</td>
</tr>
<tr class="even">
<td><strong>epsilon</strong></td>
<td>Epsilon in the insensitive-loss function used for
<code>eps-svr</code>, <code>nu-svr</code>, and <code>eps-bsvm</code>
(default: 0.1).</td>
</tr>
<tr class="odd">
<td><strong>class.weights</strong></td>
<td>A named vector of weights for different classes, used for asymmetric
class sizes. Not all factor levels have to be supplied (default weight:
1).</td>
</tr>
<tr class="even">
<td><strong>cross</strong></td>
<td>If an integer value k&gt;0 is specified, a k-fold cross-validation
on the training data is performed to assess the model’s quality:
accuracy rate for classification and Mean Squared Error for
regression.</td>
</tr>
<tr class="odd">
<td><strong>tol</strong></td>
<td>Tolerance of termination criterion (default: 0.001).</td>
</tr>
<tr class="even">
<td><strong>shrinking</strong></td>
<td>Option whether to use the shrinking-heuristics (default:
<code>TRUE</code>).</td>
</tr>
</tbody>
</table>
</div>
<div
id="svmradial---support-vector-machines-with-radial-basis-function-kernel"
class="section level2" number="10.11">
<h2><span class="header-section-number">10.11</span> svmRadial - Support
Vector Machines with Radial Basis Function Kernel</h2>
<table>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>nu</strong></td>
<td>Parameter needed for <code>nu-svc</code>, <code>one-svc</code>, and
<code>nu-svr</code>. Sets the upper bound on training error and lower
bound on fraction of data points to become Support Vectors (default:
0.2).</td>
</tr>
<tr class="even">
<td><strong>epsilon</strong></td>
<td>Epsilon in the insensitive-loss function used for
<code>eps-svr</code>, <code>nu-svr</code>, and <code>eps-bsvm</code>
(default: 0.1).</td>
</tr>
<tr class="odd">
<td><strong>class.weights</strong></td>
<td>A named vector of weights for different classes, used for asymmetric
class sizes. Not all factor levels have to be supplied (default weight:
1).</td>
</tr>
<tr class="even">
<td><strong>cross</strong></td>
<td>If an integer value k&gt;0 is specified, a k-fold cross-validation
on the training data is performed to assess the model’s quality:
accuracy rate for classification and Mean Squared Error for
regression.</td>
</tr>
<tr class="odd">
<td><strong>tol</strong></td>
<td>Tolerance of termination criterion (default: 0.001).</td>
</tr>
<tr class="even">
<td><strong>shrinking</strong></td>
<td>Option whether to use the shrinking-heuristics (default:
<code>TRUE</code>).</td>
</tr>
</tbody>
</table>
</div>
<div
id="svmradialcost---support-vector-machines-with-radial-basis-function-kernel"
class="section level2" number="10.12">
<h2><span class="header-section-number">10.12</span> svmRadialCost -
Support Vector Machines with Radial Basis Function Kernel</h2>
<table>
<colgroup>
<col width="8%" />
<col width="91%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>nu</strong></td>
<td>Parameter needed for <code>nu-svc</code>, <code>one-svc</code>, and
<code>nu-svr</code>. Sets the upper bound on training error and lower
bound on fraction of data points to become Support Vectors (default:
0.2).</td>
</tr>
<tr class="even">
<td><strong>epsilon</strong></td>
<td>Epsilon in the insensitive-loss function used for
<code>eps-svr</code>, <code>nu-svr</code>, and <code>eps-bsvm</code>
(default: 0.1).</td>
</tr>
<tr class="odd">
<td><strong>class.weights</strong></td>
<td>A named vector of weights for different classes, used for asymmetric
class sizes. Not all factor levels have to be supplied (default weight:
1).</td>
</tr>
<tr class="even">
<td><strong>cross</strong></td>
<td>If an integer value k&gt;0 is specified, a k-fold cross-validation
on the training data is performed to assess the model’s quality:
accuracy rate for classification and Mean Squared Error for
regression.</td>
</tr>
<tr class="odd">
<td><strong>tol</strong></td>
<td>Tolerance of termination criterion (default: 0.001).</td>
</tr>
<tr class="even">
<td><strong>shrinking</strong></td>
<td>Option whether to use the shrinking-heuristics (default:
<code>TRUE</code>).</td>
</tr>
</tbody>
</table>
</div>
<div id="avnnet---model-averaged-neural-network" class="section level2"
number="10.13">
<h2><span class="header-section-number">10.13</span> avNNet - Model
Averaged Neural Network</h2>
<p><em>No specific parameters provided for this model.</em></p>
</div>
<div id="nnet---neural-network" class="section level2" number="10.14">
<h2><span class="header-section-number">10.14</span> nnet - Neural
Network</h2>
<table>
<colgroup>
<col width="6%" />
<col width="93%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>linout</strong></td>
<td>Switch for linear output units. Default is logistic output
units.</td>
</tr>
<tr class="even">
<td><strong>entropy</strong></td>
<td>Switch for entropy (= maximum conditional likelihood) fitting.
Default is least-squares.</td>
</tr>
<tr class="odd">
<td><strong>censored</strong></td>
<td>Variant on <code>softmax</code>, where non-zero targets mean
possible classes. For <code>softmax</code> a row of
<code>(0, 1, 1)</code> means one example each of classes 2 and 3, but
for <code>censored</code> it means one example whose class is only known
to be 2 or 3.</td>
</tr>
<tr class="even">
<td><strong>skip</strong></td>
<td>Switch to add skip-layer connections from input to output.</td>
</tr>
<tr class="odd">
<td><strong>rang</strong></td>
<td>Initial random weights on [-<code>rang</code>, <code>rang</code>].
Value about 0.5 unless inputs are large, in which case <code>rang</code>
* max(<code>|x|</code>) should be about 1.</td>
</tr>
<tr class="even">
<td><strong>maxit</strong></td>
<td>Maximum number of iterations (default: 100).</td>
</tr>
<tr class="odd">
<td><strong>Hess</strong></td>
<td>If true, returns the Hessian of the measure of fit at the best set
of weights found.</td>
</tr>
<tr class="even">
<td><strong>MaxNWts</strong></td>
<td>Maximum allowable number of weights. Increasing <code>MaxNWts</code>
will likely slow down fitting.</td>
</tr>
<tr class="odd">
<td><strong>abstol</strong></td>
<td>Stop if the fit criterion falls below <code>abstol</code>,
indicating an essentially perfect fit.</td>
</tr>
<tr class="even">
<td><strong>reltol</strong></td>
<td>Stop if the optimizer is unable to reduce the fit criterion by a
factor of at least <code>1 - reltol</code>.</td>
</tr>
</tbody>
</table>
</div>
<div id="pcannet---neural-networks-with-feature-extraction"
class="section level2" number="10.15">
<h2><span class="header-section-number">10.15</span> pcaNNet - Neural
Networks with Feature Extraction</h2>
<p><em>No specific parameters provided for this model.</em></p>
</div>
<div id="rpart---cart" class="section level2" number="10.16">
<h2><span class="header-section-number">10.16</span> rpart - CART</h2>
<table>
<colgroup>
<col width="12%" />
<col width="87%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>minsplit</strong></td>
<td>The minimum number of observations that must exist in a node in
order for a split to be attempted.</td>
</tr>
<tr class="even">
<td><strong>minbucket</strong></td>
<td>The minimum number of observations in any terminal
<code>&lt;leaf&gt;</code> node.</td>
</tr>
<tr class="odd">
<td><strong>maxcompete</strong></td>
<td>Number of competitor splits retained in the output. Useful to know
not just which split was chosen, but which variable came in second,
third, etc.</td>
</tr>
<tr class="even">
<td><strong>maxsurrogate</strong></td>
<td>Number of surrogate splits retained in the output. Setting to zero
reduces compute time.</td>
</tr>
<tr class="odd">
<td><strong>usesurrogate</strong></td>
<td>How to use surrogates in the splitting process (0 = display only, 1
= use surrogates, 2 = use surrogates for missing primary
variables).</td>
</tr>
<tr class="even">
<td><strong>xval</strong></td>
<td>Number of cross-validations.</td>
</tr>
<tr class="odd">
<td><strong>surrogatestyle</strong></td>
<td>Controls the selection of a best surrogate (0 = total number of
correct classifications, 1 = percent correct over non-missing
values).</td>
</tr>
<tr class="even">
<td><strong>maxdepth</strong></td>
<td>Maximum depth of any node of the final tree, with the root node
counted as depth 0.</td>
</tr>
</tbody>
</table>
</div>
<div id="monmlp---monotone-multi-layer-perceptron-neural-network"
class="section level2" number="10.17">
<h2><span class="header-section-number">10.17</span> monmlp - Monotone
Multi-Layer Perceptron Neural Network</h2>
<table>
<colgroup>
<col width="16%" />
<col width="83%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>hidden2</strong></td>
<td>Number of hidden nodes in the second hidden layer.</td>
</tr>
<tr class="even">
<td><strong>iter.max</strong></td>
<td>Maximum number of iterations of the optimization algorithm.</td>
</tr>
<tr class="odd">
<td><strong>n.trials</strong></td>
<td>Number of repeated trials used to avoid local minima.</td>
</tr>
<tr class="even">
<td><strong>bag</strong></td>
<td>Logical variable indicating whether to use bootstrap aggregation
(bagging).</td>
</tr>
<tr class="odd">
<td><strong>max.exceptions</strong></td>
<td>Maximum number of exceptions of the optimization routine before
fitting is terminated with an error.</td>
</tr>
<tr class="even">
<td><strong>method</strong></td>
<td>Code <code>{&lt;link&gt;optimx}</code> optimization method.</td>
</tr>
</tbody>
</table>
</div>
<div id="mlpml---multi-layer-perceptron-with-multiple-layers"
class="section level2" number="10.18">
<h2><span class="header-section-number">10.18</span> mlpML - Multi-Layer
Perceptron, with multiple layers</h2>
<table>
<colgroup>
<col width="31%" />
<col width="68%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>size</strong></td>
<td>Number of units in the hidden layer(s).</td>
</tr>
<tr class="even">
<td><strong>maxit</strong></td>
<td>Maximum number of iterations to learn.</td>
</tr>
<tr class="odd">
<td><strong>initFunc</strong></td>
<td>The initialization function to use.</td>
</tr>
<tr class="even">
<td><strong>initFuncParams</strong></td>
<td>The parameters for the initialization function.</td>
</tr>
<tr class="odd">
<td><strong>learnFunc</strong></td>
<td>The learning function to use.</td>
</tr>
<tr class="even">
<td><strong>learnFuncParams</strong></td>
<td>The parameters for the learning function.</td>
</tr>
<tr class="odd">
<td><strong>updateFunc</strong></td>
<td>The update function to use.</td>
</tr>
<tr class="even">
<td><strong>updateFuncParams</strong></td>
<td>The parameters for the update function.</td>
</tr>
<tr class="odd">
<td><strong>hiddenActFunc</strong></td>
<td>The activation function of all hidden units.</td>
</tr>
<tr class="even">
<td><strong>shufflePatterns</strong></td>
<td>Should the patterns be shuffled?</td>
</tr>
</tbody>
</table>
</div>
<div id="evtree---tree-models-from-genetic-algorithms"
class="section level2" number="10.19">
<h2><span class="header-section-number">10.19</span> evtree - Tree
Models from Genetic Algorithms</h2>
<table>
<colgroup>
<col width="12%" />
<col width="87%" />
</colgroup>
<thead>
<tr class="header">
<th>Parameter</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>minbucket</strong></td>
<td>The minimum sum of weights in a terminal node.</td>
</tr>
<tr class="even">
<td><strong>minsplit</strong></td>
<td>The minimum sum of weights in a node in order to be considered for
splitting.</td>
</tr>
<tr class="odd">
<td><strong>maxdepth</strong></td>
<td>Maximum depth of the tree. Note that memory requirements increase by
the square of the maximum tree depth.</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="references" class="section level1" number="11">
<h1><span class="header-section-number">11</span> References</h1>
<p>Blanchet, F. G., Legendre, P., &amp; Borcard, D. (2008). FORWARD
SELECTION OF EXPLANATORY VARIABLES. <em>Ecology</em>, <em>89</em>(9),
2623–2632. <a href="https://doi.org/10.1890/07-0986.1"
class="uri">https://doi.org/10.1890/07-0986.1</a></p>
<p>Breiman, L. (2001). Random Forests. <em>Machine Learning</em>,
<em>45</em>(1), 5–32. <a href="https://doi.org/10.1023/A:1010933404324"
class="uri">https://doi.org/10.1023/A:1010933404324</a></p>
<p>Cervantes, J., Garcia-Lamont, F., Rodríguez-Mazahua, L., &amp; Lopez,
A. (2020). A comprehensive survey on support vector machine
classification: Applications, challenges and trends.
<em>Neurocomputing</em>, <em>408</em>, 189–215. <a
href="https://doi.org/10.1016/j.neucom.2019.10.118"
class="uri">https://doi.org/10.1016/j.neucom.2019.10.118</a></p>
<p>Checon, H. H., Vieira, D. C., Corte, G. N., Sousa, E. C. P. M.,
Fonseca, G., &amp; Amaral, A. C. Z. (2018). Defining soft bottom
habitats and potential indicator species as tools for monitoring coastal
systems: A case study in a subtropical bay. <em>Ocean &amp; Coastal
Management</em>, <em>164</em>, 68–78. <a
href="https://doi.org/10.1016/j.ocecoaman.2018.03.035"
class="uri">https://doi.org/10.1016/j.ocecoaman.2018.03.035</a></p>
<p>Corte, G. N., Checon, H. H., Fonseca, G., Vieira, D. C., Gallucci,
F., Domenico, M. Di, &amp; Amaral, A. C. Z. (2017). Cross-taxon
congruence in benthic communities: Searching for surrogates in marine
sediments. <em>Ecological Indicators</em>, <em>78</em>, 173–182. <a
href="https://doi.org/10.1016/j.ecolind.2017.03.031"
class="uri">https://doi.org/10.1016/j.ecolind.2017.03.031</a></p>
<p>Cortes, C., &amp; Vapnik, V. (1995). Support-vector networks.
<em>Machine Learning</em>, <em>20</em>(3), 273–297.</p>
<p>Duda, R. O., Hart, P. E., &amp; Stork, D. G. (2012). <em>Pattern
classification</em> (2nd ed.). John Wiley \&amp; Sons.</p>
<p>Pearson, Karl. (1901). LIII. On lines and planes of closest fit to
systems of points in space. <em>Philosophical Magazine Series 1</em>,
<em>2</em>, 559–572. <a
href="https://api.semanticscholar.org/CorpusID:125037489"
class="uri">https://api.semanticscholar.org/CorpusID:125037489</a></p>
<p>Fix, E., &amp; Hodges, J. L. (1989). Discriminatory Analysis.
Nonparametric Discrimination: Consistency Properties. <em>International
Statistical Review / Revue Internationale de Statistique</em>,
<em>57</em>(3), 238–247. <a href="http://www.jstor.org/stable/1403797"
class="uri">http://www.jstor.org/stable/1403797</a></p>
<p>Friedman, J. H. (2001). Greedy function approximation: A gradient
boosting machine. <em>Annals of Statistics</em>, <em>29</em>(5),
1189–1232.</p>
<p>Guo, G., Wang, H., Bell, D., Bi, Y., &amp; Greer, K. (2003). <em>KNN
Model-Based Approach in Classification</em> (pp. 986–996). <a
href="https://doi.org/10.1007/978-3-540-39964-3_62"
class="uri">https://doi.org/10.1007/978-3-540-39964-3_62</a></p>
<p>Gupta, B., Rawat, A., Jain, A., Arora, A., &amp; Dhami, N. (2017).
Analysis of Various Decision Tree Algorithms for Classification in Data
Mining. <em>International Journal of Computer Applications</em>,
<em>163</em>(8), 15–19. <a href="https://doi.org/10.5120/ijca2017913660"
class="uri">https://doi.org/10.5120/ijca2017913660</a></p>
<p>Kalcheva, N., Todorova, M., &amp; Marinova, G. (2020). <em>NAIVE
BAYES CLASSIFIER, DECISION TREE AND ADABOOST ENSEMBLE ALGORITHM –
ADVANTAGES AND DISADVANTAGES</em>. 153–157. <a
href="https://doi.org/10.31410/ERAZ.2020.153"
class="uri">https://doi.org/10.31410/ERAZ.2020.153</a></p>
<p>Kendall, M. G. (1938). A new measure of rank correlation.
<em>Biometrika</em>, <em>30</em>, 81–93.</p>
<p>Kohonen, T. (1982). Self-organized formation of topologically correct
feature maps. <em>Biological Cybernetics</em>, <em>43</em>(1),
59–69.</p>
<p>Kuhn, M. (2008). Building Predictive Models in R Using the caret
Package. <em>Journal of Statistical Software</em>, <em>28</em>(5). <a
href="https://doi.org/10.18637/jss.v028.i05"
class="uri">https://doi.org/10.18637/jss.v028.i05</a></p>
<p>Legendre, P., &amp; Anderson, M. (1999). Distance-based redundancy
analysis: testing multispecies responses in multifactorial ecological
experiments. <em>Ecological Monographs</em>, <em>69</em>(1), 1–24. <a
href="https://doi.org/10.1890/0012-9615"
class="uri">https://doi.org/10.1890/0012-9615</a></p>
<p>MacQueen, J. (1967). Some methods for classification and analysis of
multivariate observations. <em>Proceedings of the Fifth Berkeley
Symposium on Mathematical Statistics and Probability</em>, <em>1</em>,
281–297.</p>
<p>Melssen, W., Wehrens, R., &amp; Buydens, L. (2006). Supervised
Kohonen networks for classification problems. <em>Chemometrics and
Intelligent Laboratory Systems</em>, <em>83</em>(2), 99–113. <a
href="https://doi.org/10.1016/j.chemolab.2006.02.003"
class="uri">https://doi.org/10.1016/j.chemolab.2006.02.003</a></p>
<p>Pearson, K. (1920). Notes on the History of Correlation.
<em>Biometrika</em>, <em>13</em>, 25–45.</p>
<p>Shepard, D. (1968). A two-dimensional interpolation function for
irregularly-spaced data. <em>Proceedings of the 1968 23rd ACM National
Conference On -</em>, 517–524. <a
href="https://doi.org/10.1145/800186.810616"
class="uri">https://doi.org/10.1145/800186.810616</a></p>
<p>Shepard, R. N. (1962). The analysis of proximities: Multidimensional
scaling with an unknown distance function. <em>Psychometrika</em>,
<em>27</em>(2), 125–140.</p>
<p>Sneath, P. H. A. (1957). The application of computers to taxonomy.
<em>Journal of General Microbiology</em>, <em>17</em>(1), 201–226.</p>
<p>Spearman, C. (1987). The Proof and Measurement of Association between
Two Things. <em>The American Journal of Psychology</em>,
<em>100</em>(3/4), 441–471. <a
href="http://www.jstor.org/stable/1422689"
class="uri">http://www.jstor.org/stable/1422689</a></p>
<p>Vieira, D. C., Brustolin, M. C., Ferreira, F. C., &amp; Fonseca, G.
(2019). segRDA: An &lt;scp&gt;r&lt;/scp&gt; package for performing
piecewise redundancy analysis. <em>Methods in Ecology and
Evolution</em>, <em>10</em>(12), 2189–2194. <a
href="https://doi.org/10.1111/2041-210X.13300"
class="uri">https://doi.org/10.1111/2041-210X.13300</a></p>
<p>Vieira, D. C., Gallucci, F., Corte, G. N., Checon, H. H., Zacagnini
Amaral, A. C., &amp; Fonseca, G. (2021). The relative contribution of
non-selection and selection processes in marine benthic assemblages.
<em>Marine Environmental Research</em>, <em>163</em>, 105223. <a
href="https://doi.org/10.1016/j.marenvres.2020.105223"
class="uri">https://doi.org/10.1016/j.marenvres.2020.105223</a></p>
<p>Yao, M., Zhu, Y., Li, J., Wei, H., &amp; He, P. (2019). Research on
Predicting Line Loss Rate in Low Voltage Distribution Network Based on
Gradient Boosting Decision Tree. <em>Energies</em>, <em>12</em>(13),
2522. <a href="https://doi.org/10.3390/en12132522"
class="uri">https://doi.org/10.3390/en12132522</a></p>
</div>
</div>

   
   
            
      

  <script>
    $(document).ready(function () {

			
 		
	    });
  </script>



    <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
	var script = document.createElement("script");
	script.type = "text/javascript";
	script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
	document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>
  
</body>
</html>
